{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_trading3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgDYpJI4xYrj9sau/8J23K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushweigelt/personal_ml_projects/blob/master/ml_trading/ml_trading3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Z2FMrFEbg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ed7378e6-abc8-4cab-c9e7-12ee0ce50d4c"
      },
      "source": [
        "#mount personal google drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm6dt8-FEgFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ba15695c-3343-422c-bf67-dd848a2ba72a"
      },
      "source": [
        "%cd drive\n",
        "%cd My\\ Drive\n",
        "%cd ml_trading"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/ml_trading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7foz_34qFNIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "4315b04a-81f1-4108-f464-dd9b99b0a9a3"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install yahoo_fin"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.29.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Collecting yahoo_fin\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/e8/b42de33475fb22ea051753a64c1b101ee901df88013801f722001998b36d/yahoo_fin-0.8.5-py3-none-any.whl\n",
            "Installing collected packages: yahoo-fin\n",
            "Successfully installed yahoo-fin-0.8.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhZqlIx2Eijb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6f302179-849b-4507-f064-0ed496cc9f75"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning - Certain functionality \n",
            "             requires requests_html, which is not installed.\n",
            "             \n",
            "             Install using: \n",
            "             pip install requests_html\n",
            "             \n",
            "             After installation, you may have to restart your Python session.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss4ZPtsHElOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seed, so we can get the same results after rerunning several times\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fykXi-QSEo8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
        "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
        "    last_sequence = list(sequences) + list(last_sequence)\n",
        "    # shift the last sequence by -1\n",
        "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    # split the dataset\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "    # return the result\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tNWQK-Esds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYc83RDSEvVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Window size or the sequence length\n",
        "N_STEPS = 100\n",
        "# Lookup step, 1 is the next day\n",
        "LOOKUP_STEP = 1\n",
        "# test ratio size, 0.2 is 20%\n",
        "TEST_SIZE = 0.2\n",
        "# features to use\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "# date now\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "### model parameters\n",
        "N_LAYERS = 3\n",
        "# LSTM cell\n",
        "CELL = LSTM\n",
        "# 256 LSTM neurons\n",
        "UNITS = 256\n",
        "# 40% dropout\n",
        "DROPOUT = 0.4\n",
        "# whether to use bidirectional RNNs\n",
        "BIDIRECTIONAL = False\n",
        "### training parameters\n",
        "# mean absolute error loss\n",
        "# LOSS = \"mae\"\n",
        "# huber loss\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "# Apple stock market\n",
        "ticker = \"AAL\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "# model name to save, making it as unique as possible based on parameters\n",
        "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1YTi5kPEyMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create these folders if they does not exist\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQUdN32eEz24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "856d49d1-ef3d-4044-921b-38883d205269"
      },
      "source": [
        "# load the data\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "# save the dataframe\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "# some tensorflow callbacks\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)\n",
        "\n",
        "model.save(os.path.join(\"results\", model_name) + \".h5\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 2/45 [>.............................] - ETA: 8s - loss: 0.0752 - mean_absolute_error: 0.2926WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.136819). Check your callbacks.\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.1017\n",
            "Epoch 00001: val_loss improved from inf to 0.00363, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 7s 150ms/step - loss: 0.0113 - mean_absolute_error: 0.1017 - val_loss: 0.0036 - val_mean_absolute_error: 0.0628\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0732\n",
            "Epoch 00002: val_loss improved from 0.00363 to 0.00300, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0051 - mean_absolute_error: 0.0732 - val_loss: 0.0030 - val_mean_absolute_error: 0.0560\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0634\n",
            "Epoch 00003: val_loss improved from 0.00300 to 0.00155, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0038 - mean_absolute_error: 0.0634 - val_loss: 0.0016 - val_mean_absolute_error: 0.0410\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0550\n",
            "Epoch 00004: val_loss improved from 0.00155 to 0.00151, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0030 - mean_absolute_error: 0.0550 - val_loss: 0.0015 - val_mean_absolute_error: 0.0408\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0512\n",
            "Epoch 00005: val_loss improved from 0.00151 to 0.00149, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0025 - mean_absolute_error: 0.0512 - val_loss: 0.0015 - val_mean_absolute_error: 0.0420\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0454\n",
            "Epoch 00006: val_loss improved from 0.00149 to 0.00091, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0020 - mean_absolute_error: 0.0454 - val_loss: 9.1096e-04 - val_mean_absolute_error: 0.0322\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0438\n",
            "Epoch 00007: val_loss improved from 0.00091 to 0.00083, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0019 - mean_absolute_error: 0.0438 - val_loss: 8.2595e-04 - val_mean_absolute_error: 0.0305\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0402\n",
            "Epoch 00008: val_loss did not improve from 0.00083\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0015 - mean_absolute_error: 0.0402 - val_loss: 8.6677e-04 - val_mean_absolute_error: 0.0315\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0408\n",
            "Epoch 00009: val_loss improved from 0.00083 to 0.00063, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 0.0016 - mean_absolute_error: 0.0408 - val_loss: 6.2674e-04 - val_mean_absolute_error: 0.0263\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0380\n",
            "Epoch 00010: val_loss improved from 0.00063 to 0.00048, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0014 - mean_absolute_error: 0.0380 - val_loss: 4.7991e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0380\n",
            "Epoch 00011: val_loss did not improve from 0.00048\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0014 - mean_absolute_error: 0.0380 - val_loss: 0.0012 - val_mean_absolute_error: 0.0387\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0362\n",
            "Epoch 00012: val_loss did not improve from 0.00048\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0362 - val_loss: 8.1791e-04 - val_mean_absolute_error: 0.0311\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0384\n",
            "Epoch 00013: val_loss did not improve from 0.00048\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0014 - mean_absolute_error: 0.0384 - val_loss: 8.5046e-04 - val_mean_absolute_error: 0.0324\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0382\n",
            "Epoch 00014: val_loss improved from 0.00048 to 0.00038, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 0.0014 - mean_absolute_error: 0.0382 - val_loss: 3.7563e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0357\n",
            "Epoch 00015: val_loss did not improve from 0.00038\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0357 - val_loss: 4.8039e-04 - val_mean_absolute_error: 0.0232\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0344\n",
            "Epoch 00016: val_loss improved from 0.00038 to 0.00036, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 0.0012 - mean_absolute_error: 0.0344 - val_loss: 3.5576e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0339\n",
            "Epoch 00017: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0011 - mean_absolute_error: 0.0339 - val_loss: 4.2011e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0334\n",
            "Epoch 00018: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0334 - val_loss: 6.7309e-04 - val_mean_absolute_error: 0.0288\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0334\n",
            "Epoch 00019: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0334 - val_loss: 5.0869e-04 - val_mean_absolute_error: 0.0243\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 9.6796e-04 - mean_absolute_error: 0.0316\n",
            "Epoch 00020: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.6796e-04 - mean_absolute_error: 0.0316 - val_loss: 6.1526e-04 - val_mean_absolute_error: 0.0261\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0322    \n",
            "Epoch 00021: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0010 - mean_absolute_error: 0.0322 - val_loss: 4.2874e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0329\n",
            "Epoch 00022: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0011 - mean_absolute_error: 0.0329 - val_loss: 3.7403e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 9.9251e-04 - mean_absolute_error: 0.0324\n",
            "Epoch 00023: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.9251e-04 - mean_absolute_error: 0.0324 - val_loss: 8.7574e-04 - val_mean_absolute_error: 0.0316\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0327\n",
            "Epoch 00024: val_loss did not improve from 0.00036\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0011 - mean_absolute_error: 0.0327 - val_loss: 3.6521e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0330\n",
            "Epoch 00025: val_loss improved from 0.00036 to 0.00031, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0010 - mean_absolute_error: 0.0330 - val_loss: 3.1112e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 9.7283e-04 - mean_absolute_error: 0.0316\n",
            "Epoch 00026: val_loss improved from 0.00031 to 0.00031, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.7283e-04 - mean_absolute_error: 0.0316 - val_loss: 3.1017e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 9.6482e-04 - mean_absolute_error: 0.0316\n",
            "Epoch 00027: val_loss did not improve from 0.00031\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.6482e-04 - mean_absolute_error: 0.0316 - val_loss: 3.6963e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.6828e-04 - mean_absolute_error: 0.0302\n",
            "Epoch 00028: val_loss improved from 0.00031 to 0.00027, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.6828e-04 - mean_absolute_error: 0.0302 - val_loss: 2.6897e-04 - val_mean_absolute_error: 0.0180\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.4785e-04 - mean_absolute_error: 0.0300\n",
            "Epoch 00029: val_loss did not improve from 0.00027\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.4785e-04 - mean_absolute_error: 0.0300 - val_loss: 2.9726e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.9546e-04 - mean_absolute_error: 0.0309\n",
            "Epoch 00030: val_loss improved from 0.00027 to 0.00025, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.9546e-04 - mean_absolute_error: 0.0309 - val_loss: 2.5286e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 9.9631e-04 - mean_absolute_error: 0.0320\n",
            "Epoch 00031: val_loss did not improve from 0.00025\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.9631e-04 - mean_absolute_error: 0.0320 - val_loss: 8.3418e-04 - val_mean_absolute_error: 0.0323\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 9.6662e-04 - mean_absolute_error: 0.0314\n",
            "Epoch 00032: val_loss improved from 0.00025 to 0.00025, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.6662e-04 - mean_absolute_error: 0.0314 - val_loss: 2.5077e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.0453e-04 - mean_absolute_error: 0.0291\n",
            "Epoch 00033: val_loss did not improve from 0.00025\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 8.0453e-04 - mean_absolute_error: 0.0291 - val_loss: 4.3807e-04 - val_mean_absolute_error: 0.0235\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.2023e-04 - mean_absolute_error: 0.0292\n",
            "Epoch 00034: val_loss improved from 0.00025 to 0.00024, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.2023e-04 - mean_absolute_error: 0.0292 - val_loss: 2.3981e-04 - val_mean_absolute_error: 0.0162\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.8684e-04 - mean_absolute_error: 0.0288\n",
            "Epoch 00035: val_loss did not improve from 0.00024\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.8684e-04 - mean_absolute_error: 0.0288 - val_loss: 4.5460e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.9828e-04 - mean_absolute_error: 0.0305\n",
            "Epoch 00036: val_loss did not improve from 0.00024\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.9828e-04 - mean_absolute_error: 0.0305 - val_loss: 2.7039e-04 - val_mean_absolute_error: 0.0177\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.3373e-04 - mean_absolute_error: 0.0295\n",
            "Epoch 00037: val_loss did not improve from 0.00024\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 8.3373e-04 - mean_absolute_error: 0.0295 - val_loss: 3.3741e-04 - val_mean_absolute_error: 0.0193\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.0490e-04 - mean_absolute_error: 0.0285\n",
            "Epoch 00038: val_loss did not improve from 0.00024\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.0490e-04 - mean_absolute_error: 0.0285 - val_loss: 3.8471e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.2171e-04 - mean_absolute_error: 0.0273\n",
            "Epoch 00039: val_loss did not improve from 0.00024\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.2171e-04 - mean_absolute_error: 0.0273 - val_loss: 8.8229e-04 - val_mean_absolute_error: 0.0324\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.5143e-04 - mean_absolute_error: 0.0282\n",
            "Epoch 00040: val_loss did not improve from 0.00024\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.5143e-04 - mean_absolute_error: 0.0282 - val_loss: 2.4037e-04 - val_mean_absolute_error: 0.0165\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.5851e-04 - mean_absolute_error: 0.0280\n",
            "Epoch 00041: val_loss improved from 0.00024 to 0.00023, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 7.5851e-04 - mean_absolute_error: 0.0280 - val_loss: 2.2600e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.6082e-04 - mean_absolute_error: 0.0279\n",
            "Epoch 00042: val_loss improved from 0.00023 to 0.00021, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.6082e-04 - mean_absolute_error: 0.0279 - val_loss: 2.1218e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.0286e-04 - mean_absolute_error: 0.0267\n",
            "Epoch 00043: val_loss did not improve from 0.00021\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.0286e-04 - mean_absolute_error: 0.0267 - val_loss: 2.5363e-04 - val_mean_absolute_error: 0.0164\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.1156e-04 - mean_absolute_error: 0.0274\n",
            "Epoch 00044: val_loss did not improve from 0.00021\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.1156e-04 - mean_absolute_error: 0.0274 - val_loss: 2.3261e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.4100e-04 - mean_absolute_error: 0.0278\n",
            "Epoch 00045: val_loss did not improve from 0.00021\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.4100e-04 - mean_absolute_error: 0.0278 - val_loss: 2.6466e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.1174e-04 - mean_absolute_error: 0.0274\n",
            "Epoch 00046: val_loss improved from 0.00021 to 0.00020, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 7.1174e-04 - mean_absolute_error: 0.0274 - val_loss: 2.0328e-04 - val_mean_absolute_error: 0.0150\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.8285e-04 - mean_absolute_error: 0.0266\n",
            "Epoch 00047: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.8285e-04 - mean_absolute_error: 0.0266 - val_loss: 2.4613e-04 - val_mean_absolute_error: 0.0171\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 8.0360e-04 - mean_absolute_error: 0.0293\n",
            "Epoch 00048: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.0360e-04 - mean_absolute_error: 0.0293 - val_loss: 3.5342e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.3914e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00049: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.3914e-04 - mean_absolute_error: 0.0258 - val_loss: 2.4435e-04 - val_mean_absolute_error: 0.0163\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.2076e-04 - mean_absolute_error: 0.0275\n",
            "Epoch 00050: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.2076e-04 - mean_absolute_error: 0.0275 - val_loss: 3.9323e-04 - val_mean_absolute_error: 0.0222\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.8688e-04 - mean_absolute_error: 0.0273\n",
            "Epoch 00051: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.8688e-04 - mean_absolute_error: 0.0273 - val_loss: 2.1539e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.9961e-04 - mean_absolute_error: 0.0270\n",
            "Epoch 00052: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.9961e-04 - mean_absolute_error: 0.0270 - val_loss: 2.2619e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.3965e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00053: val_loss did not improve from 0.00020\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.3965e-04 - mean_absolute_error: 0.0258 - val_loss: 2.1550e-04 - val_mean_absolute_error: 0.0154\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.3368e-04 - mean_absolute_error: 0.0260\n",
            "Epoch 00054: val_loss improved from 0.00020 to 0.00018, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 6.3368e-04 - mean_absolute_error: 0.0260 - val_loss: 1.8300e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.2848e-04 - mean_absolute_error: 0.0255\n",
            "Epoch 00055: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.2848e-04 - mean_absolute_error: 0.0255 - val_loss: 2.1652e-04 - val_mean_absolute_error: 0.0163\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.1404e-04 - mean_absolute_error: 0.0276\n",
            "Epoch 00056: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.1404e-04 - mean_absolute_error: 0.0276 - val_loss: 2.7237e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.5495e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00057: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.5495e-04 - mean_absolute_error: 0.0283 - val_loss: 2.0957e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.0525e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00058: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.0525e-04 - mean_absolute_error: 0.0252 - val_loss: 1.9105e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.0167e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00059: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.0167e-04 - mean_absolute_error: 0.0252 - val_loss: 1.9637e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 60/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.2547e-04 - mean_absolute_error: 0.0255\n",
            "Epoch 00060: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.2547e-04 - mean_absolute_error: 0.0255 - val_loss: 2.6740e-04 - val_mean_absolute_error: 0.0171\n",
            "Epoch 61/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.9174e-04 - mean_absolute_error: 0.0248\n",
            "Epoch 00061: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.9174e-04 - mean_absolute_error: 0.0248 - val_loss: 2.4303e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 62/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.2012e-04 - mean_absolute_error: 0.0280\n",
            "Epoch 00062: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.2012e-04 - mean_absolute_error: 0.0280 - val_loss: 2.7870e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 63/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.6069e-04 - mean_absolute_error: 0.0267\n",
            "Epoch 00063: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 6.6069e-04 - mean_absolute_error: 0.0267 - val_loss: 1.9133e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 64/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.5323e-04 - mean_absolute_error: 0.0264\n",
            "Epoch 00064: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.5323e-04 - mean_absolute_error: 0.0264 - val_loss: 1.9734e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 65/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 7.1606e-04 - mean_absolute_error: 0.0271\n",
            "Epoch 00065: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 7.1606e-04 - mean_absolute_error: 0.0271 - val_loss: 4.3303e-04 - val_mean_absolute_error: 0.0241\n",
            "Epoch 66/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.1376e-04 - mean_absolute_error: 0.0254\n",
            "Epoch 00066: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.1376e-04 - mean_absolute_error: 0.0254 - val_loss: 3.0384e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 67/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.6605e-04 - mean_absolute_error: 0.0270\n",
            "Epoch 00067: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.6605e-04 - mean_absolute_error: 0.0270 - val_loss: 1.9025e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 68/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.1779e-04 - mean_absolute_error: 0.0254\n",
            "Epoch 00068: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.1779e-04 - mean_absolute_error: 0.0254 - val_loss: 3.1492e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 69/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6103e-04 - mean_absolute_error: 0.0240\n",
            "Epoch 00069: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.6103e-04 - mean_absolute_error: 0.0240 - val_loss: 2.0624e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 70/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6909e-04 - mean_absolute_error: 0.0249\n",
            "Epoch 00070: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.6909e-04 - mean_absolute_error: 0.0249 - val_loss: 3.0752e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 71/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.2279e-04 - mean_absolute_error: 0.0260\n",
            "Epoch 00071: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.2279e-04 - mean_absolute_error: 0.0260 - val_loss: 2.1068e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 72/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.0544e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00072: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.0544e-04 - mean_absolute_error: 0.0258 - val_loss: 2.2855e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 73/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.9824e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00073: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.9824e-04 - mean_absolute_error: 0.0256 - val_loss: 2.5198e-04 - val_mean_absolute_error: 0.0170\n",
            "Epoch 74/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6664e-04 - mean_absolute_error: 0.0248\n",
            "Epoch 00074: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.6664e-04 - mean_absolute_error: 0.0248 - val_loss: 1.9014e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 75/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6434e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00075: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.6434e-04 - mean_absolute_error: 0.0244 - val_loss: 2.0303e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 76/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.5136e-04 - mean_absolute_error: 0.0241\n",
            "Epoch 00076: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.5136e-04 - mean_absolute_error: 0.0241 - val_loss: 2.2532e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 77/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.5751e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00077: val_loss improved from 0.00018 to 0.00018, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 5.5751e-04 - mean_absolute_error: 0.0244 - val_loss: 1.7782e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 78/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.5666e-04 - mean_absolute_error: 0.0243\n",
            "Epoch 00078: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.5666e-04 - mean_absolute_error: 0.0243 - val_loss: 1.8908e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 79/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.3214e-04 - mean_absolute_error: 0.0242\n",
            "Epoch 00079: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.3214e-04 - mean_absolute_error: 0.0242 - val_loss: 2.0522e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 80/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.1989e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00080: val_loss did not improve from 0.00018\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.1989e-04 - mean_absolute_error: 0.0237 - val_loss: 2.1546e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 81/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.2422e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00081: val_loss improved from 0.00018 to 0.00017, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 116ms/step - loss: 5.2422e-04 - mean_absolute_error: 0.0238 - val_loss: 1.6630e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 82/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.2533e-04 - mean_absolute_error: 0.0235\n",
            "Epoch 00082: val_loss did not improve from 0.00017\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.2533e-04 - mean_absolute_error: 0.0235 - val_loss: 1.6926e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 83/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.2915e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00083: val_loss improved from 0.00017 to 0.00016, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.2915e-04 - mean_absolute_error: 0.0237 - val_loss: 1.5999e-04 - val_mean_absolute_error: 0.0135\n",
            "Epoch 84/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.4723e-04 - mean_absolute_error: 0.0261\n",
            "Epoch 00084: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.4723e-04 - mean_absolute_error: 0.0261 - val_loss: 5.1307e-04 - val_mean_absolute_error: 0.0261\n",
            "Epoch 85/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 6.4806e-04 - mean_absolute_error: 0.0264\n",
            "Epoch 00085: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.4806e-04 - mean_absolute_error: 0.0264 - val_loss: 3.1507e-04 - val_mean_absolute_error: 0.0200\n",
            "Epoch 86/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.0426e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 00086: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.0426e-04 - mean_absolute_error: 0.0232 - val_loss: 2.9469e-04 - val_mean_absolute_error: 0.0180\n",
            "Epoch 87/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6073e-04 - mean_absolute_error: 0.0241\n",
            "Epoch 00087: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.6073e-04 - mean_absolute_error: 0.0241 - val_loss: 2.3983e-04 - val_mean_absolute_error: 0.0171\n",
            "Epoch 88/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.3667e-04 - mean_absolute_error: 0.0240\n",
            "Epoch 00088: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.3667e-04 - mean_absolute_error: 0.0240 - val_loss: 1.9254e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 89/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.2961e-04 - mean_absolute_error: 0.0243\n",
            "Epoch 00089: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.2961e-04 - mean_absolute_error: 0.0243 - val_loss: 1.7534e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 90/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.5385e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00090: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.5385e-04 - mean_absolute_error: 0.0244 - val_loss: 3.2208e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 91/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6788e-04 - mean_absolute_error: 0.0248\n",
            "Epoch 00091: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.6788e-04 - mean_absolute_error: 0.0248 - val_loss: 1.6464e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 92/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 4.9919e-04 - mean_absolute_error: 0.0233\n",
            "Epoch 00092: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 4.9919e-04 - mean_absolute_error: 0.0233 - val_loss: 2.4025e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 93/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.1012e-04 - mean_absolute_error: 0.0235\n",
            "Epoch 00093: val_loss improved from 0.00016 to 0.00016, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 5.1012e-04 - mean_absolute_error: 0.0235 - val_loss: 1.5784e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 94/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 4.7875e-04 - mean_absolute_error: 0.0228\n",
            "Epoch 00094: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 4.7875e-04 - mean_absolute_error: 0.0228 - val_loss: 3.4754e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 95/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.0851e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00095: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.0851e-04 - mean_absolute_error: 0.0237 - val_loss: 1.7510e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 96/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6954e-04 - mean_absolute_error: 0.0249\n",
            "Epoch 00096: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.6954e-04 - mean_absolute_error: 0.0249 - val_loss: 2.2373e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 97/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.6113e-04 - mean_absolute_error: 0.0250\n",
            "Epoch 00097: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.6113e-04 - mean_absolute_error: 0.0250 - val_loss: 3.5786e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 98/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.3222e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00098: val_loss improved from 0.00016 to 0.00016, saving model to results/2020-06-08_AAL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 5.3222e-04 - mean_absolute_error: 0.0244 - val_loss: 1.5598e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 99/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.1114e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00099: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.1114e-04 - mean_absolute_error: 0.0238 - val_loss: 1.6891e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 100/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 5.1783e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00100: val_loss did not improve from 0.00016\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.1783e-04 - mean_absolute_error: 0.0237 - val_loss: 2.0233e-04 - val_mean_absolute_error: 0.0150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8AFV9P-E3SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorboard --logdir=\"logs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7We1veGE4sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "#Dont run unless loading previous trained weights\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg_13w8bE6e-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc50c8aa-3da5-4698-d20f-a70d1babbdf4"
      },
      "source": [
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "# evaluate the model\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "# calculate the mean absolute error (inverse scaling)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.5312027323912316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25RZiZwpE8kG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, data, classification=False):\n",
        "    # retrieve the last sequence from data\n",
        "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
        "    # retrieve the column scalers\n",
        "    column_scaler = data[\"column_scaler\"]\n",
        "    # reshape the last sequence\n",
        "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
        "    # expand dimension\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "    # get the prediction (scaled from 0 to 1)\n",
        "    prediction = model.predict(last_sequence)\n",
        "    # get the price (by inverting the scaling)\n",
        "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    return predicted_price"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXxB40PE_Ph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e79d3fcd-de99-4798-a95b-974f2797b3c1"
      },
      "source": [
        "# predict the future price\n",
        "future_price = predict(model, data)\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 1 days is 20.11$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLRLo3ovMjJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(model, data):\n",
        "  y_test = data[\"y_test\"]\n",
        "  X_test = data[\"X_test\"]\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "  y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "  # last 200 days, feel free to edit that\n",
        "  plt.plot(y_test[-200:], c='b')\n",
        "  plt.plot(y_pred[-200:], c='r')\n",
        "  plt.xlabel(\"Days\")\n",
        "  plt.ylabel(\"Price\")\n",
        "  plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtzeorSyMqqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2ec1b511-ea51-4fc3-dd02-580142a05cb3"
      },
      "source": [
        "plot_graph(model, data)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3iUVfbHPzeF0EvoPUjvoXfpTVwUFXvBxbb2ta1lV9ld17p2fxZQV7EgigUVEDGAKAhIk96lt0AIARJImfP748ykkAQSkskkzPk8zzzvvPdtZ2aS73vec88914kIhmEYRvAQEmgDDMMwjKLFhN8wDCPIMOE3DMMIMkz4DcMwggwTfsMwjCAjLNAG5IVq1apJVFRUoM0wDMMoUSxduvSgiFQ/tb1ECH9UVBRLliwJtBmGYRglCufc9pzaLdRjGIYRZJjwG4ZhBBkm/IZhGEFGiYjxG4ZRNKSkpLBr1y5OnDgRaFOMfFC6dGnq1atHeHh4nvY34TcMI51du3ZRoUIFoqKicM4F2hwjD4gIhw4dYteuXTRq1ChPx1ioxzCMdE6cOEHVqlVN9EsQzjmqVq2ar6c0E37DMLJgol/yyO9vZsIfhKSkwNtvQ1JSoC0xDCMQmPAHIZMnw223wYQJue9z4gRcey3MnFl0dhmGj6+//hrnHOvXrz/jvi+//DKJiYlnfa3333+fO++8M8f26tWrEx0dTatWrZiQyz/MN998wzPPPHPW1w8EJvxByKef6nLCBMhtHp633oKPP4bLRwu7x0+Dzp2hWjXo0AH27y86Y42gZNKkSfTu3ZtJkyadcd+CCv/puOKKK1ixYgVz587l0UcfZf8pf/upqamMHDmShx9+2C/X9xcm/EFGXJx68Q0bwurVsHzWQRgwAP72N9i5E4Bjx+Cpp6Bb5zReT76FurdeSPyuo6ReMhrWrYOxY3O/YxhGATl27Bi//PIL7777Lp/6vBQgLS2NBx54gDZt2tCuXTtee+01Xn31Vfbs2UP//v3p378/AOXLl08/ZsqUKYwZMwaAb7/9lm7dutGhQwcGDRqUTcRPR40aNWjcuDHbt29nzJgx3HbbbXTr1o2HHnooyxPD/v37GTVqFO3bt6d9+/YsWLAAgI8++oiuXbsSHR3NrbfeSlpaWkG/pgJh6ZxBxhdfQGoqvP8+jBgBWx7/gI6L5sBPP8FHH8GmTbz+elniYlNZ2/5aqp2czIRqj3DH/nG0XFSKWQ+0pMZ/7oHzz4euXeG55yA0NNAfy/AD994LK1YU7jmjo+Hll0+/z9SpUxk2bBjNmjWjatWqLF26lE6dOjF+/Hi2bdvGihUrCAsLIy4ujsjISF588UXmzJlDtWrVTnve3r17s3DhQpxzvPPOOzz33HO88MILebJ769atbN26lSZNmgCa9rpgwQJCQ0N5//330/e7++676du3L1999RVpaWkcO3aMdevWMXnyZObPn094eDi33347H3/8Mddff32eru0PzOMPMr76Cpo0gb59YdTFQtsl7yE9esDs2bBnD6kvv86rL3uYUXss1X6cDM89x00HnuKLb0qxezc0ffUudl37N0hIgBdf1BuGYRQikyZN4sorrwTgyiuvTA/3/Pjjj9x6662Eham/GhkZma/z7tq1i6FDh9K2bVuef/551qxZc8ZjJk+eTHR0NFdddRVvv/12+jVHjx5NaA4Oz+zZs/nLX/4CQGhoKJUqVSImJoalS5fSpUsXoqOjiYmJYevWrfmyvbAxjz/I2LgRunQB5+CapotpkbaW7QPG07BvXxg2jLSnnuXD4zMZyGz497/hwQdxwJ/+BMuWwaBBjpZfP8NP0/9Bx6HV4csvNVRkFBlbtujvOHy4f69zJs/cH8TFxTF79mxWrVqFc460tDScczz//PN5Pkfm1MbMue133XUX9913HyNHjmTu3LmMGzfujOe64ooreP3117O1lytXLs/2iAg33HADTz/9dJ6P8Tfm8QcRHo+G8Rs00PW+2z4gkTJMCb0CAPn3k4Qdj6dt2DrklVfhsceyHN+gAcydC+Hh8Oq75WDYMH2E8HiK+JMENw8/rDfiHTsCbUnhM2XKFK677jq2b9/Otm3b2LlzJ40aNeLnn39m8ODBvP3226SmpgJ6kwCoUKECR48eTT9HzZo1WbduHR6Ph6+++iq9/ciRI9StWxeADz74wC/2Dxw4kDfffBPQPokjR44wcOBApkyZwoEDB9Lt3r49x2rJRYbfhN85V9o5t9g597tzbo1z7p/e9kbOuUXOuc3OucnOuVL+ssHIyv79kJysHbsAZRfPZUmFAXw3ryIAS6QTTdjM1Je34e6+Sx8LTqFOHejYUft4ueQS2LMHFi8uwk8R3KSlQUyMLl95JdDWFD6TJk1i1KhRWdouvfRSJk2axE033USDBg1o164d7du355NPPgHglltuYdiwYemdu8888wwXXnghPXv2pHbt2unnGTduHKNHj6ZTp05n7A84W1555RXmzJlD27Zt6dSpE2vXrqVVq1Y8+eSTDBkyhHbt2jF48GD27t3rl+vnGRHxywtwQHnv+3BgEdAd+Ay40tv+FvCXM52rU6dOYhSchQtFQOTbb0UkIUHEOZnZ658SHi5y9KjIffeJhIeLHD58+vPceadIhQoinrjDesBDDxWJ/YbIokX6G9asqb9BfHzhnn/t2rWFe0KjyMjptwOWSA6a6jeP33vdY97VcO9LgAHAFG/7B8DF/rLByIrv6bJhQzRgL0L14Z1JSYHPPtOBXcOHQ+XKpz9Py5Zw9CjsSawM3brBzz/73XZD+eEHXX7wgf4GXqfXMPKFX2P8zrlQ59wK4AAwC9gCxItIqneXXUDdXI69xTm3xDm3JDY21p9mBg2+mHCDBsBvvwHQ9sbO9OihI3l37wZvMsVpadlSl+vWAd27600kOdkvNhtZmTVLQ21Dh0KtWrBwYaAtMkoifhV+EUkTkWigHtAVaJGPY8eLSGcR6Vy9era5gosHCQlw8cXw+++BtiRPbN8OlSrpiyVLoEEDwurU4NNPoXx5KFNGOw3PRBbh79YNTp4sMd9BSeb4cfj1Vxg8WNc7dIDly7HOdSPfFElWj4jEA3OAHkBl55wvjbQesLsobCgsVqyAVq1UKCd2fwOmTtXMlhLAjh0ZGT0sWaJ5nWjbjBkaNsg06DFXatbUcNDatajwg7meRcDq1Vpgr0cPXR9RaymvreqH1KoFc+YE1jijROHPrJ7qzrnK3vdlgMHAOvQGcJl3txuAqf6yobBZu1a9raNHoc15iQxf/6JuWLkysIblkR07vPH9uDhNBu/cOX1bt2768JIXnFOvf906oF49TfVZtMgvNhc2CQleL7kEsm6dLlu1Ao4c4dZPzqclazlZprL+YU4tMf9KRoDxp8dfG5jjnFsJ/AbMEpHvgL8B9znnNgNVgXf9aEOhcs89KnqzZ8Pf675HdYlFzjuvxAj/9u1ej9/nnXftetbnShd+5/SuUUI8/ocegl691HMuaaxdCxER0KgRsGQJYScTuZaP+PT+JdC8Ofz971ZDycgT/szqWSkiHUSknYi0EZF/edu3ikhXEWkiIqNF5KS/bChMkpI0eeW666BpU+i87kOW0InEy8fA1q1a2awYc/QoHD7sFf6YGFUQX8zgLGjZEg4cgEOHUOHfsgV27So0e/1BcrJmLyUlZWQ4lSTWrlV9DwsjvXN+Y4XOLF5fER58UGNBMTGBNbIQCA0NJTo6mjZt2jB69OgCVd4cM2YMU6ZoEuFNN93E2rVrc9137ty56UXV8kNUVBQHDx7Msb1t27a0a9eOIUOGsG/fvhyPv+CCC4iPj8/3dQuCjdzNI/Pnax/mwIHAgQPU3PEbU7mIw3XbqpeVh7ofgcRbeFNDPbNnQ8+e2pt7lrRvr8vly9GBXBERcPvt2T3OI0fO+hqFhYj2f86cqTc/0PtUSWPduoyOdZYsgcaNieoYybJlaDpWjRrw0kuBNLFQKFOmDCtWrGD16tWUKlWKt956K8t238jd/PLOO+/QqlWrXLefrfCfjjlz5rBy5Uo6d+7MU089lWWbiODxeJg+fTqVz5RDXciY8OeRmBj1tM4/H5gxAyfCNEawt3o73aGYh3u2bdPleRUPag/1wIEFOl/HjrpcuhR9BHrqKfj2W/U8ly/nrrvgfxd9DZGR8G5go3n33qtdEf/6F5Qtq22bNwfUpDPi+718JCbCH3944/ugHn/nznTsqAlVJ11pvfFOn178P1w+6NOnD5s3b2bu3Ln06dOHkSNH0qpVK9LS0njwwQfp0qUL7dq14+233wZUTO+8806aN2/OoEGD0sskAPTr148lS5YA8P3339OxY0fat2/PwIED2bZtG2+99RYvvfQS0dHR/Pzzz8TGxnLppZfSpUsXunTpwvz58wE4dOgQQ4YMoXXr1tx0002+Aaun5fzzz2fz5s1s27aN5s2bc/3119OmTRt27tyZ5Ylh4sSJ6SOTr7vuOoBc7SgIVqQtj8TEaESjfHlg2jSSq9dheWwHdoUJXcqXh1WrAm3iadmwQZct9nqzPwoo/FWrQlSUV/hB1XXePHjhBXjhBRqGP8Iwz0R1te++WwPrLXLJ5l29WvMUK1TI20CCfPDjj/Dqq5rCumQJ3HqrVp8+VRtF4OBBKA6Zw4sW6fCI2bPBW4WADRvUxlat0Bjbjh1w990MaqlO/ty5MPTmm7Ww3oQJ8OyzBTckUHWZvaSmpjJjxgyGDRsGwLJly1i9ejWNGjVi/PjxVKpUid9++42TJ0/Sq1cvhgwZwvLly9mwYQNr165l//79tGrVij//+c9ZzhsbG8vNN9/MvHnzaNSoUXp559tuu43y5cvzwAMPAHD11Vfz17/+ld69e7Njxw6GDh3KunXr+Oc//0nv3r15/PHHmTZtGu/mwbH57rvvaNu2LQCbNm3igw8+oHv37ln2WbNmDU8++SQLFiygWrVq6bWI7rnnnhztKAgm/Hng8GEVuL//He0VnDmT5Asuh08dB+MctGlT7D3+DRvU+a74W4wKbKaMnrOlc+dMwh8SAl9/DXv3cvCmh3lg+tN4cJyc9CURd96sk7f88guH4hzjx+tApBEj4J6Itwi7O1OIqFs3b+9lwTlxAm66CZo103JCn30GI0fC778cZfgXf4X6reCOOyAigjfegPvv10FsVasWyuXPmhkzdDl3bobw+0LTrVqhdzCAzp3p31Ujdt9+C0OH1tEP+L//6eNNRERRm14oJCUlER0dDajHP3bsWBYsWEDXrl1p5P3b+OGHH1i5cmV6/P7IkSNs2rSJefPmcdVVVxEaGkqdOnUYkEPl2IULF3L++eennyu38s4//vhjlj6BhIQEjh07xrx58/jyyy8BGDFiBFWqVMn1s/Tv35/Q0FDatWvHk08+SXx8PA0bNswm+qAlnUePHp1eR8hnV252lM9L7nUumPDngblz1XEdNAh1wxISCB91IXyqXiIdO+o/27Zt6gYXQzZsgBbNBb7/XtUkrOA/fadOMGWK3hirVNFO09Cqtfnf+f8jcXoUCVTk2uaj6PDvfXD77cjPv3DRo32YP1+4q+ZnNJzzOWF8QcrQEYQ//ij07g0TJ8ITTxTCJ4Zp07QTd/p0qHRwCzc/OxSmteH9vftpHrcQ7gfGjydt4W/8978VOHkSti/YTdV+FfXmGCBmz9Zl5gzZdet0vpsmTYDPFms2VceOlCmjmZzffguvvQbu1lt1XMkXX8DVVxfMkEDUZSYjxn8qmUshiwivvfYaQ4cOzbLP9OnTC80Oj8fDwoULKV269Fmf49QJYuLj4/NV0rmw7DgVi/HngZgYjQ1364bGCSpXJuKiYZQr5xX+hx5SIR0zptiOoly/HgbWWKVKmJfhuXmgUydd/vIL/Oc/ULu21vqZPTeE58v9kxe5Xz3VMWOgWjX23fcc8+fDnOvf59X9VzKiygJedn/l8rCv8HTvqXX9P/ig0L7DTz7RwWZDusbDhRdqCtK8eTSOX8rlYV+QNuVL2LCBjX95kW3boDO/0W50M7j55kK5PmjUZePGvO+fmKiZsc7pU4rvQWjWLH2wLFUKzdfv0iX95uQr0bxqFXoXaNVKwzSndhScQwwdOpQ333yTFG9e7saNGzl+/Djnn38+kydPJi0tjb179zInh4Ft3bt3Z968efzxxx9A7uWdhwwZwmuvvZa+7rsZnX/++emVQWfMmMFhX8ZAARkwYACff/45hw4dymJXbnYUiJwqtxW3V6Crc7ZoITJsmIgcOyZSrpzIzTeLiEjDhiLXXefd6d13tWziG28EysxcOXJETftp8L/1zd69hXLegwf1dOHhuuzcWZcgcuONIqGhIo89pvum/GOcCMj/VX9CPOXLi/TrJ5KaKq+9pvtPmCAiEyd6Df2pwLbFx4tERIjcc7dH5MIL1ci5c0WOHpVPnt4mILJ9u4hccokcDy0vd1aaKPuoodcvW1YkMbHANhw/rqe78868HzNrlh5zySW63LhR5Lff9P2rr4rIqlWZVpQ9e7TpkUe8DevXi1SqJNKunUhycr5sLg7VOcuVK5etbc6cOTJixIj09bS0NHnkkUekTZs20rp1a+nXr5/Ex8eLx+ORO+64Q5o1ayaDBg2S4cOHy+effy4iIn379pXffvtNRESmT58u0dHR0q5dOxk0aJCIiGzYsEHatm0r7du3l3nz5klsbKxcfvnl0rZtW2nZsqXceuutIiJy8OBBGTx4sLRq1UpuuukmadCggcTGxmazuWHDhtna//jjD2ndunWu+73//vvSunVradeundxwww0iIrnacSr5qc4ZcFHPyyuQwr9rl35Lzz8vIh9/nEWYOnUSGT5cJDZW5IeZHknu01+kalWRuLiA2esjPl7kxAl9v3ixmh3XtItIt26Fep3oaJEmTURmzxbxeESGDtVrffKJ3jBHjdL95n19SBbQXTdWriyyY4eI6DGNGolcdJHojbVsWZG77iqwXf/7n17qj/te1TevvJK+LSZGm2JiRNZ+tV5SCBUB2enqyeTzX9eNX39dYBvWr9dTDR2a92MeeUQkLExk/nw99sMPRcaMUX8jPl5EHn5Y76j792c57oorRMqU0ZtEnz4is2+ZpCf44Yd82VwchN84O0z4CxGfE7psmYgMHizSoIFIWpqI6D90ly76AAAiHdxy8Tinhe0DSHKySFSUyJVX6vrEiSItWaNG/uc/hXqtxESRlJSM9V27RG6/Xcv9jxql4i8i8m/vw0b879tEtm3Lco6bblIHNTVV9Ett1arAdg0fLnJRnUXiiYgQGTFC7zBetm9XW956S59MRkTMkoSvYyS6TYqMujBZb0xjxpzVdTNdRn74Qa/TqFHej+/bV+/Nqakq9n+OXiIzQ4bKhEGfihw4IFK/vsgFF2Q7bts2fcIJ1XuY9OuWqDfR22/Pl/0m/CUXE/5C5IYb1IlPW7k6m3Bec43+U7drpzeA7t1FPoz4s3jCw7N5ZEXC6tUiBw7Ip5+qqU3ZKAkDL5atDfpKMmHiKVtWZNOmIjPnscdUiE6eVCE+5Qk3nUle53TxYhF57jld2bPnrK975IhIVPguiS9XW3+gUx6309J0IpNatVQs//IXbb/wQpH27UXk2mv1R898RzsDyckiV18t0qFDRts77+hHCQnJePo6E/Xr69+ciMi41p/JCUpJMmGSHlNzTmTatByPHTdOpHRpkf79ddeUCy8WqVcv693oDJjwl1yKxUQs5wIi2rHbvz+EvP4qlC4Nt9ySvr16ddi3TwftDhkCb7wBT518AJeSolk+RUBamvfNzp2aX9m+PTH/WUjDBsJ7IWMJ+ymGpKOpfFz5TtymTd60kKKhZUu1b+NGTdPv2TPn/XwpizExZEzc7kttyQd/+xtccQXMmObhvZRrKec5Ct98A6dMsxcSotcqV07LONx1l7Y3aOCds+Dii7UjOI8TzIjANddoZ/Ly5RnVO3yjpT0erepxJpKTNZ3Ulxj2cMq/SD6vBWF7d8F//6udzmvWwAUX5Hj8449riv+DD2rW8YYWF2kZjWXL8vQ5Mj6P1fspaeT7N8vpblDcXoHy+DdsUEfrw6d3qit1yy1Ztj/5pKR3Zn7xhbbdeKPIHNdPkus3Sg8J+YvkZHXoHnhARMaOFSlVSpLqNJKThMuW1n8SARnLBAGRSy/1qyk5snGjOqgjRuh39P77ue/bpo1G0iQ1VaRKFf0i88GWLepZg8gDlcaLgKS9PeG0xxw+LLJkScb6M8/o8Ql7j+nvfffdebq2rw+lRw9dLl+u7TfemPH3kZcugy1bdN/33hPtgAeRZ5/Nkw2ZOXJEn7Seui9Wv5R//CPPx27dulViY2PFk4+nBCOweDweiY2Nla1bt2bbRi4ev+Xxn4aYGGjAdq54Y4Cma95/f5btmR1JX2rjk0/CI5/cRr+dV2oC+YUX+s2+RYvUofv2v+t51v0Pd9ddXL70ca44+ADXrPkfqR270viSP/PJeRmTdxQlTZvCjTfCe+/pem4eP6ijP2ECpHhCCe/fX798kRwnfM+JZ5/Vn6hvsz08tvpB1tfqR4ubx572mMqVM343yJiEfvvBcrQZPFgHpL388hlt+PFHXT7xBAwf5mH70kNEt6/Gzp2OFi00lTYvKZ2+7MuoKDKKrQ0adOYDT6FiRR1aMuO3ajwSHZ2vyqn16tVj165d2Kx3JYvSpUtTr169vB+Q092guL0C5fFfNipV1oS3E0/lyjpT+SlMmaJOWdWqWcOoTz5+UrbQSE5G1hTJ4S5cWDzxhEhZlyhry3WSeCrK7ZftFxB5800RWbNG8y0DzJ49IuXLi1SvfvpQ8+TJ+l0uWSIZwfFffsnzNUqVErntNpH4AaMkkdKy8MON+bbVl0kzbZqo2+016NdfNXaf20PIwIHaz3Pib4/LCUrpcS++KM2aiYweLVKjhnZgnwlfRvDWraKdy5GRZ/3U+OCD+p2kXH2dSJ06Z3UOo+SDde7mj9RUkXvLvq1fkTcP+FTmztXNgwdnbT9+XKRnlbVyNLyKSLNm2ToXC4tevUSmVtN4wj87TxUQ6djRmx1TjPjyS80sOh3btul3+frrommdlSuLXH65iJz58/hCbnte0zux5+lnzspOX+ruG2+I/mYhIbJ7zKPinIasypQROZGU6e6VkiLJ99wvMW6gzO1wrwjItIhRsi2yg3jq15dyESly//0ivXuLXNlls+Zq5uBA+PjHPzQyk3zSozG80aPP6nOIZGSjxT7gjV8dPnzW5zJKLib8+SAtTWTCC0dkHzVkf/M+ubqqa7wZkg8/nH3bHXeIDCj1s6YTdu+ud4NCJCFB5LKQL9SAv/9dPB6NI5+SKVli8Hg0y+baa70NDzwgEhoq37yxUypW1HFLmVm1SjNrf/1VE3du7rxMpEIFvfPlc9CSj9RUzaFP/z0vuEASIypJg7DdMvHdZHmMf0tKmfKaejNggEjXriIge6mpv8PIkXJ+r1R5pNXXIiCX8rm88orIxO7/J6l4OyCuvjr9eosXizRtqlmaIjoYsEEDEVm3TtLzTc+SadP0FBte+DZfT0/GuYUJfz647jqRu3hFBOTo7EW57peYqI/5mTsIffzyi367c+/+Qt3FkSPzlR54JmZ+clD2UUMSmnQ4a6Erblx8sQqhiIj88YdISIhMbnC/gHb+Jh73iCQliYjIf/8r6WPBOrJEEivVVEHeubNANrRsqXru8YjIxo1ywkXIikp9JLVlaxGQNU1Gilx7rXi6dZPjtRrJ8y3fkYjQFDk+4yeRpCS58UaROjVT5USdKFlKB1n6lwmSFhIq33GBpHbrqSPevPzzn/oZvvpK1/v0ETn//Ewf7o8/zvpz/PqrnmLOe1v1zdtvF+h7MUomJvx5JDFRY6PbIqPFU4DrpqWp9zZ8uEh6XYJbby2UTB+PR2RS48ckhVA5sWhFgc9XXHj6af2afF0Tx0dfLycoJdd3XSf/x18koVwt3aFVK/m8zTg5r+xeedg9LScoJZ669UQKIQd9vCYEybffiuzbJ/I3vEY1bSqPtvpKOnbUnPwxYyS9ukPmpJmnnvI62LdOTB8RfLheaylPghy84T7NFvLGrkaN0n19x9evL3L99aLq365dgT7Hxo167g8/SFMj85ihZJxbmPDnkdmzRdqzXDICzmfPQw9p6CA2VuTgzQ+LgKReeJHm2xWAiRNF5tNDdkf1LNB5ihtz5ujX3ru3et73XbFLjlFW0sqWEwH5svSVkvbYP0QGDZL0PEmQ3V0uKrSO7ORkkcaNdSDXhAkijjRZ/958keTk9NHHjRplCPapA7M++0y33XijSCQH5cibH8uvX+wWEFn9V2+n9ebNIpJxnhEjdJBbSIjI0w8eylrk6Czx1VF65RXR0YUDBxbofEbJxIQ/jzz+uMgr3C2eUqVEDh0q0LmWe+8fb74pct21HrmHlyTVhWpv8FnmSa9eLVK70nFJcWGS9lAOnQslmKNH9WmrdGlNRAGRV2s/JeKc/HbrhPT6OkeOiHRloczv9aDGNAoZn3g7p9lIvoe0Vat0RGzfviLTp+d8rO83h4xBs1u90ZZvHlngffONxMdnXKN27Ywc/rk3f6RvTtMJnBdSU/Xcjz8u+nhSq1aBzmeUTIJX+D0eTdPIY7z0gh5xcjS0YkahmwLg8Witmo4dVcwqVxa5jTckW8ddQoLW9zlDZc916/T/97JIb5Wx3NSnBLNsmcju3fqUdP31IlO/9ogcOCCJiZoWOnZsRjZVLpULCoUff9Rqo6d23J+pm+bYMR1/1qdPxp/cyZNq79N/O6xvnnlG5s3Tt0OGSHoIvisLJaFpR60nUQghwchITTKQ55/XixTQkTFKHsEr/EuX6sfs0EH/A09DYqLIv0Ke0P1XFE7s/F//yvAAf/5ZpEVzj8wOGySppctqcZXnn9eKaqBubi5PAi+9pOmE1aqJ7L9jnLpz8fGFYmNJ4brrtJjbE0/o17VvX6Atypljx7Lrds2aetOSOnVEbrhBXvUWDfXVVRpdRrNvPJUrn36Icz5o0kTkqqtE5JtvCuUpwih5BK/wP/ywiiRo0P00/DT1sBymkuztfvHZX+8UNm3KuO+IaLpl5zq7ZUbYiIw7QufO2vELWkhlgcYAACAASURBVCfiFHzZfcOHa665DBiQtRpYkPDLLxnVJ+vVC7Q1+aNzZ/XuE3sNlG01u8iwYRpGSkjQfoQVtJPDNZtpvKuQ6NZNrykrV+qXNnlyoZ3bKBnkJvzndpE2EZ1odfBgnfP1hRdgz55cdz8x7hkqc4QKzz9eaCY0aaLFs557TtcbNoRP59XhvVHf0TlyK03D/uDbx3+D++7THebOzXYO34j7F16AupFJWvHs/PMLzcaSQq9eWh6hatWMwm4lhfr1tbzGiuRWVN2/lu+/F9q310m07q77Je1ZSYXnHocCzKN6KlWraq259FoU5/CMXEb+OLeFf/lyLYs4erSWbkxLgw8/zHHXlHWb6bv8JX5qeD3lencoVDP++c+sJVcaN9b70Y9bGlGlQxSXXgrbwpvq3IU5CP/ixVp/pXlz1P6kJLjkkkK1saTQr59WvXz77UBbkj/q1VO7f0nsSHmOM73nk/zj0rVw5528ePhGUhq3IPSaKwv1mpGREBeH/vFUqaLTbhoG57rwf/65zlB98cVaMaxPH60YJpJt10M3PUQypUh64pkiM69yZfi//9MSur+vdOrGzp2bzb5Fi3SK1RA88NJLWlmsT58is7O4UaaMvkoS9evD0aPwry3XsrDZ9Qxf8Djn/6U1TJhAyKWjCJ8+Vf9WC5F0jx/U6zfhN7yc08I/92QPZnZ+LKOM5tixWibxl1+y7rh3LzUWfM3bEffQ/+raRWpjekXI7ag7u3dvllKOSUmwciV07QrMmKGlHu+7L89VK43iQf36ujx2Ioz1f/ufzk7/7LMa/5k4EZo1K/RrRkZCQoI6FjRsaKEeI51zWvinh41k5PJ/ZkxWctll6ipOmZJlv7VPTCYE4fgl1xERUbQ2Vq+uJqULP2QJ9yxfDqmp0K0b8NFHULOmhq6MEoVP+AG69wyBRx+Fhx7SPwA/UbWqLg8fRms9b9+e49OuEXyc08LfooXOapTu6JQrp0Xhf/oJ0JmKRoyA4+9OYn2ZDtw/vnmR2+iczvy0fTvaE1ynThbhX7xYl127iM5KNWQIhIcXuZ1GwfCVSq9c2S/OfY74hD+9g/fYMe9dwAh2znnhB9iwIVNj376wciXHdx3mhRfgyNLNdPEspvb9VxVmQkW+aNjQO+Wfyx7nnz1bbwy149bovHq+qQmNEkWdOvrzdu2qUz8WBZGRurTMHuNUzmnhb+514Nevz9TYty+IsGfyz4jAW4O/AKDSzVcUvYFesvS79eunE/lu2MCePTqJ15VXkjEHbUnLYzQAfUgbM0ZnJCsqfB5/XBwZE/laB68B5/bUi1Wrar9uFuHv2hUiIjj5w0/ASBqv+w46dFC3OkA0bKjOfFISlMkU53/vYAvS0nSObR6YrXmgPs/NKHH4pqAsKrKEenqZx29kcE57/ED6nKfplC4N3btTacVP1CkdR+nlCzTQH0B8Wr5jB9C4MSk167J1Qgzjx2v+f5OoVA3/WJjHyAdZQj2RkdrHZR6/QZAIf5YYP0D//tQ5sJznKv0H5/EUG+Hfvh1wji/dZUQt+4J2O7/jrruAcePgyBG46KIAWmmUNCpU0Ano4+LQDgZfZo8R9ASF8B844P3j93HXXewNqcc1+1/UdLouXQJmH2REmXbs0PD+mH1Ps7dWB76pcA0jp1yvOd9jxwb8BmWULJzLYRCXhXoMgkD4fR28mb3+2LRIRns+JS0kTMW0kEdM5pe6ddWE7dvh22/hBGU4+sFXhHSIhu+/h4ED4bXXAmqjUTJJL9sANnrXSMdvwu+cq++cm+OcW+ucW+Ocu8fbPs45t9s5t8L7usBfNkBGSufvv2e0rV4NC+nB4lcXwfPP+/PyeSIsTMV/+3aYOhUaNYLmgxvoeIMDB7QyWUmrUWAUC7J4/FFRmsefkBBIk4xigD89/lTgfhFpBXQH7nDOtfJue0lEor2v6X60gUaNoE0brZDpK8y5apUuG47qmFHOIcC0aweTJsHMmTBypFVkMAqHyMhTQj1gXr/hP+EXkb0issz7/iiwDqjrr+vlRmgoTJ4Mx4/D9ddr2/LlUKOGFsMsLrz3nuZ5h4TA1VcH2hrjXKFq1VNCPWDCbxRNjN85FwV0ABZ5m+50zq10zr3nnKuSyzG3OOeWOOeWxMbGFuj6rVrB3/8OMTGwezcsWwYdOxYvr7p6dZgwQXP5u3YNtDXGuUK2UA9YB6/hf+F3zpUHvgDuFZEE4E2gMRAN7AVeyOk4ERkvIp1FpHP1Qihk5auHHxMDa9ao8BdHimo4vxEcREaqM5GUhD7mRkSYx2/4V/idc+Go6H8sIl8CiMh+EUkTEQ8wASgS/zY6GsqWhbfe0vlYiqvwG0ZhkqVsQ0iIZfYYgH+zehzwLrBORF7M1J45sj4KWO0vGzITHq6ljX/9VddN+I1gIEvZBrBcfgPwr8ffC7gOGHBK6uZzzrlVzrmVQH/gr360IQu9e+uycuWMcKdhnMtkKdsA5vEbgB+LtInIL0BO3ad+Td88HT7hL24du4bhL7KEekA9nvSKgDY2JFgJqq7E7t015GNZM0awkGOoB8zrD3LO6bLMp1Kxosb4mzQJtCWGUTRkC/X45oDctStjWLsRdASV8AN06hRoCwyj6ChTRl/poZ5atXS5b1/AbDICT1CFegwjGMlStsE3XH3v3oDZYwQeE37DOMfJMnq3QgUd0GIef1Bjwm8Y5zhZ6vU4p+Ee8/iDGhN+wzjHyRLqAQ33mMcf1JjwG8Y5TpZQD5jHb5jwG8a5ji/UI+JtMI8/6DHhN4xznMhISE2Fo0e9DbVqQXy8t2SnEYyY8BvGOU620bu+lM79+wNijxF4TPgN4xzHV5BwwwZvg28Ql8X5gxYTfsM4x+nUSbM4Fy/2Nvg8fovzBy0m/IZxjlOxIrRsmUn4zeMPekz4DSMI6NZNhV8EnYIxJMQ8/iDGhN8wgoCuXSE21luNOTRUxd88/qDFhN8wggDfHBRZwj0m/EGLCb9hBAFt20JExCkdvCb8QYsJv2EEAeHh0KYNrFrlbahbF3bvDqhNRuAw4TeMIKFu3UxOft26OvduSkpAbTICgwm/YQQJdeqcIvwiFu4JUkz4DSNIqFMHDh6E5GRU+AH27AmoTUZgMOE3jCAhy4DdOnV0xeL8QYkJv2EECT6t37OHDI/fhD8oMeE3jCDB5/Hv2QNUqwalSpnwBykm/IYRJPg8/r170aptdeqY8AcpJvyGESRUr67VGtL7c+vWtc7dIMWE3zCChJCQUyo1mMcftJjwG0YQUafOKR7/7t2ZJuM1goU8Cb9zrplzLsY5t9q73s4593f/mmYYRmFTu/Ypwn/8OCQkBNQmIxeSk3V0dWpqoZ86rx7/BOARIAVARFYCVxa6NYZh+JVso3fBwj3FlRUroGZN+P77Qj91XoW/rIgsPqWt8G9DhmH4ldq1cxi9u2tXQG0ycuHwYV1GRhb6qfMq/Aedc40BAXDOXQZYkQ/DKGH4Ujr37QPOO09X/vgjYPYYp8En/FWqFPqpw/K43x3AeKCFc2438AdwbaFbYxiGX8lcqaFBtzpQujRs3hxYo4yciYvTZaCEX0S2AoOcc+WAEBE5WuiWGIbhd7KE9UNCoHFjE/7iih89/rxm9TzlnKssIsdF5Khzropz7slCt8YwDL9Sv74u08P6TZqY8BdTjmw/zMmwsvy+PqLQz53XGP9wEYn3rYjIYeCC0x3gnKvvnJvjnFvrnFvjnLvH2x7pnJvlnNvkXRb+7cwwjBypUgXKlIGdO70NTZrAli3g8QTULiM7x3ceJja1CvHxZ943v+RV+EOdc+m3HedcGeBMt6FU4H4RaQV0B+5wzrUCHgZiRKQpEONdNwyjCHAO6tXL5PE3bgxJSTYhSzEkNTaOw1RJL65XmORV+D8GYpxzY51zY4FZwAenO0BE9orIMu/7o8A6oC5wUaZjPwAuPhvDDcM4O+rXPyXUAxbuKY4cPkwckYETfhF5FvgP0NL7+reIPJfXizjnooAOwCKgpoj43It9QM1cjrnFObfEObckNjY2r5cyDOMMZPH4TfiLLaEJhzkaWoUKFQr/3HlN50REZgAz8nsB51x54AvgXhFJcM5lPqc453IsFCIi49EUUjp37mzFRAyjkKhXT7N60tIgtH59CA/XOL9RrIg4HsfJsh39cu7TevzOuV+8y6POuYRMr6POuTMW+HDOhaOi/7GIfOlt3u+cq+3dXhs4ULCPYBhGfqhXT0V//34gLAwaNTKPvxhS9uRhUisV/qhdOIPwi0hv77KCiFTM9KogIhVPd6xT1/5dYJ2IvJhp0zfADd73NwBTz958wzDyS7aUzmbN4PffA2aPkQPJyZT1HMf5IYcf8hDjd86FOufWn8W5ewHXAQOccyu8rwuAZ4DBzrlNwCDvumEYRUS9erpMT+kcPhw2boQ1awJmk5EVidPBW2HVAyT8IpIGbHDONcjPiUXkFxFxItJORKK9r+kickhEBopIUxEZJCJxZ229YRj5xif86R7/pZfqKN7JkwNmk5GVYztV+EvVCkCoJxNVgDXemvzf+F5+scgwDL9StaqW6EkX/po1oV8/+Owzm5SlmHBoswp/uXr+8fjzmtXzD79c3TCMIifbIC6Ayy+H226DlSuhffuA2WYoR/7QQEjFhgEI9TjnSjvn7gVGAy2A+SLyk+/lF4sMw/A7LVrAjBmwerW34ZJLdCb2zz4LqF2G4gv1VG4UmBj/B0BnYBUwHHjBL1YYhlGkvPYalC0Lw4ZBbCxQvToMGKBxfgv3BJykvSr8NVoEJsbfSkSuFZG3gcuAPn6xwjCMIiUqSjV+926YOdPbePnlOpBr+fJAmmYAqQdU+MvXq+yX859J+FN8b0TEplo0jHOIbt10/FZ6FueoUdpg4Z6A4zkYxzFXARee5+IK+eJMwt8+82hdoF1+Ru4ahlF8KVUKmjdX4U9KgrvGVeVE74Hw5ZdnPtjwKyFHDnO0lH/CPHDmkbuhp4zWDcvryF3DMIo/rVur8M+aBa+/DqtrDoJNm7z1HIxAUer4YU6U8d9UJXnN4zcM4xykdWuda33aNF3fUquXvpk/P3BGGZQ+cZiUcib8hmH4gTZtNInn4491fX3ZjhARYcIfQE6cgApp8UjFSn67hgm/YQQxrVvr8vhxXR48GgFdusCCBYEzKsjZvx8qcQRXxT8ZPWDCbxhBTePG2snrIy4O6NkTli7VHl+jyPEJf1hV8/gNw/ADYWE6ird0aWjbFg4fBnr1gpQUWLIk0OYFJft2p1GJBCJqmsdvGIafuOEGuOMOqF3b6/H36KEbFi0KqF3ByuEdRwEoW9t/Hr9/RgcYhlFiuO8+XV55pWb4UL26VnGzEbwBIWFHPADl61qoxzAMPxMZ6Q31AHToYMIfII7tPgJAeHUL9RiG4Wd8wi+CCv+GDZCYGGizgo4T+9Tjp5J5/IZh+JkqVXQS9qNHUeH3eLQ+v1GknDygHj+VzeM3DMPPRHpLw8TFocIPsGJFwOwJVtLivMJvHr9hGP6mirdCwOHDQIMG2mBx/qLniIV6DMMoIrJ4/M5BdDSeZctp1gymTAmoaUFDUhJEnDCP3zCMIsLn8cfFeRs6dMCtWsXWTal88UXAzAoq9u+HysSTWqpM1iHVhYwJv2EYQIbHnzml0508QQvWW822ImLfPi3XkFrOf94+mPAbhuElJ48foAPL2bkTduwIjF3BRFycCr9U9F9GD5jwG4bhpUwZrcic7vE3b05qeGk6oB285vX7n8REDfV4/FiSGUz4DcPw4px6/ekef1gYh+q0owPLCQkx4S8KkpLU4/dnDj+Y8BuGkYksZRuAXdU7EM0KevcS9v+4Sks2W0+v30hKUo/f+TGjB0z4DcPIRGRkJo8f2FyhA1WI56GwF/nfhh7w66/w7ruBM/Acx+fxh1Qx4TcMo4ioUgX27oXkZF1fU0o7eEfMeYDVtCHl4tEwb17GDkah4vP4Q6taqMcwjCKiRQtYv14H7q5dCyvS2rK9dDPW97mZvvxE/PCrdJ7GxYtZsQIOHQq0xecWyUdPUpqThPpx9i0w4TcMIxPPPAPTp+tAoq++gr3xZbit3wZW3z2eZCI40LKv9gLHxDBoEFxzjffAyy+HV14JqO3nAhKvo3ZDKpvwG4ZRRISEwPDhUKcObN4MBw9CtWoZ1QPiiISOHUmdNZtDh2DmTFgxaR18/rneMU6DiLfks5Erzlenx7J6DMMoapo0UeE/dAiqVs3Qofh4YOBAQhfO52kephLxrPn7J7px+/ZczycCV10Fl13mf9tLMiFH/V+nB2zqRcMwcqBJE5g6VWvzV6uWIfxHjgAPPcT+33by0JznuKz8TEK3er3U7dtV4Z3Ldr4pU2DyZH2SMHIn9Kj/K3OCefyGYeRAkyYZHbdVq2boUHy8Nsy84RMuYDqNElfTiG2caNMZTpzQzoFTSEiAu+/W9/v2QWpq0XyGkkipY95cWl/hJD/hN+F3zr3nnDvgnFudqW2cc263c26F93WBv65vGMbZ06RJxvvMMf4j3kjE7t0wk2EsvOMjYhjAvqv+qhtyCPcsWqSCf/HFOqlXDvcGw0vE8Ux3Wz/iT4//fWBYDu0viUi093X63iDDMAJCZuGvWlVr+JQu7fX4UeGvUgUS/3QFg4jhUJ22umHbtmzn8hV3Gzgw41gjZ8oklnDhF5F5QNwZdzQMo9jRuHHG+2rVdFm5cobHv2sX1KsH5crpelyFhvomF+F3Drp2zTjWyJmySXEkhpb3ay1+CEyM/07n3EpvKKhKAK5vGMYZqFgRqlfX9z7ns3LlrB5/3boZwp9ARY1L5yL8depAw4YZxxo5U/7kIY6V8q+3D0Uv/G8CjYFoYC/wQm47Ouducc4tcc4tiY2NLSr7DMPw4gv3+IS/UqXswl++vK4fPw5EReUY49+xQ0cCV68OkWEJDH55BKxb53f7SyIVkg9xrPQ5Jvwisl9E0kTEA0wAup5m3/Ei0llEOlf3uR6GYRQZTZqoR1+6tK77Qj0pKdpBm9njP34cdelz8Ph37lThDwmBSyvH0GLrdBvlmwsVUw6RVMa/GT1QxMLvnKudaXUUsDq3fQ3DCCz33w9vvZWx7vP49+7VdP1swh8VpcKfaXiuSIbHD9A//Bd9M3mypn8aWaiYFkdS2RLs8TvnJgG/As2dc7ucc2OB55xzq5xzK4H+wF/9dX3DMApG+/Zw7bUZ6z6P3xejr1cPypbV9+nCn5SkdR68xMbCyZNQv76udzo5n6MhFfUO8t13RfI5ShJVPIc4Wa4EC7+IXCUitUUkXETqici7InKdiLQVkXYiMlJE9vrr+oZhFC6+zl2f8NetC6GhGgo6fhxo1Eg3bN6cfowvlbNBAyAxkcbxS5kQehtSpw5MnFik9hd3JDWNKhwmuUIJFn7DMM4tKlVS733LFl2vW1eX5crBsWNAs2basGlT+jFZhH/xYkI9qcSknE/y0D/Bzz9b1bZMnNwfTwhCaiUTfsMwigm+ej3z5mmGji/bp1y5TB5/aChs3Jh+TBbh/0Xj+wvoyeEaLfTxwQr6p3Nyj34XJvyGYRQbfGUb5s2DTp0yarGVL+8V/lKl4LzzYMOG9GN27tR+gMhIYOFCjke1Ip4q7C3fVHfIdJMIdpL36XhXqXKOZfUYhlFy8Xn8x46p8PtI9/hBwz2nePz163tvEmvX4mmtpR3+CM8eFgp2Uverxy+R5vEbhlFMyDw3SMeOGe+zCf+mTVqNDU39rF0bzfbZto1S7VsCsCUtKltYKNhJO6DC76qZ8BuGUUzIXCL+tB5/UlJ66s+xY1r+gQ0bQISI6FaULw+7D4RrWMg8/nQ8sSr8IdVN+A3DKCb4PP6qVTMGZMEpwt+8uS69cf5jx7xlHXwlGlq2pFYtLdNM06bm8Wfm0CHSCCHMzxOtgwm/YRh5xOfxZ+7YhUzpnJCR0ukV9HThX7tWazY0bUrt2hoCSg8LWUqncjiOOCIpU87/smzCbxhGnihfXrNz+vTJ2p7F469TR9N4ThX+deu01nNERFaPPzER9uwpyo9RbAk5fEiFv4z/r2Vz7hqGkSecgzVrss8KmEX4nYNWrWDpUjwe1fV04W+pHbu1a8P335N1wJdvNFgQExZ/iENUpUoRCL95/IZh5JlatbLPEVK+vFbsTEnxNgwbBgsWkLTzICJQoUyqirtX+GvV0kncE+t7+wPWrCm6D1BcWbSIKluXsJu6ReLxm/AbhlEgslToBLjoIvB4SJ06DYC6J7boXSGTxw+wN7SeJvn/9FMRW5wDgexnWLMG+vfnRLmqPMLTJvyGYRR/sgl/p05Qty6h06YCUOfQSm1v0wZQjx9g334H/fvDnDnpef8B4emnNbU0UGWiv/sOkpL49Na5bKGJCb9hGMWfbMLvHIwcSZl5MylNErV3L4Xw8HThT/f49wIDBmgZ50CFez76CB59VOcRWL8+MDYsWwaNGnEgQmtXm/AbhlHsySb8ABddROiJRPozh6rbl0HbthARAWTy+PehHj/A7NlFZm86R4/CLbdAixa6vjpA80ItXQodO5KUpIOZw8P9f0kTfsMwCoRP+NNz+QH69iUtogzDmUHFzUuz1HioVk0Fbt8+dCRY48Ya7ilCPv8cxvWYqaOMX3tN1TYQTx3x8VrnulMnkpKKxtsHE37DMApIjh5/6dIcaN2fa/iY8IS4LDUeQkOhRg1vqAegXz8t+XmaDtalS2HoUNXpwuCHH6DxmqmkVKqq12/ePDAe/4oVuuzYkRMnTPgNwyghlC+vyyzCD+xoNZxIDutK5uI+aJx/3z7vSpcucPhwRvH+HPjuOxVrn04WlJ1bU7iQ71h73p8gLEz7H4pK+D/+GL74Qju0ly3Ttg4dzOM3DKPkkKPHD2xqPAwACQvTGH8matXSwb27dqGT+8JpVd1X4n/lyoy2W2+F5547O5trrJ9HFeL57ORF2tCmjXbwHj16difMKwcPwvXXw2WXQXQ0TJqkkxfXqGHCbxhGySE34d9dpgmbaIK0bK0T82aiVy+dmrdBA5i1r61mAp1G+H213HzCv2ABjB8P8z7ZBX/6U8ZEwHnA44Gu+6aSSBle2zCEhASgdWvduHZtns9zVkyfrgaMGwfJybBkCXTuDGDCbxhGySE34T9+HK7nQ9z4t7Md8+ijmj0pAotWl9PyDbkIv0h24X/iCV223DhV40CPPZZne/fuEUZ6vmZN3SEcTSvL3Lmkp5r6M9wjAmlfTtXyFI8/rp3JU6fC888DJvyGYZQgypbV5anCf+wYrKnQHde9W47HNW+uc/fu2IGGPXIR/v37NQJTpowK//z58OOPmgzULmmh7jRxYtY40GmI/WE5DdhJ2CUXUaqUdyrgRo30An7M7Jk4/gRJU2eSMnykPuGEhsLIkdCkCWDCbxhGCSI0VCM5WdI5yVSZ8zTUr6/z8hIdrTH2+Phs+/ji+yNGQEIC3HuvFor717+gOwtJ6NRPa0aPG5cne0O+m0oaIZS/8kIaNtTLEhqq1UL9ODHM/k9iKM9xtrYdmeP2Y8dM+A3DKEFkqdDpJS/C36BBJuEH+P33bPv4wjyXXabLJUu0Y7djg4M0ZTNbmw2HG2+EadPy1Dlb89ev+YXe1OtQnagor/CDet5+FP7qK2NIojSLyvTPti0hQR82TukD9xsm/IZhFJgKFVS8MpNvjx8y0hszsXGjDvodPlzXw8Lg9tuh0YFFAPxepjsbWo/SztIZM05/wW+/pea+lfxQ4TLKlCGr8DdtClu3Qmrq6c9xFsTHQ6v4+SymKys3RGTbPneuXnbIkEK/dI6Y8BuGUWDq1fOmZmYir8KfkABHytSChg01XecUNm5UTa5YUQcAX3edXi9i+UJSCeXnxE6MeLInh0KqI199lfvF4uLgllvYUr4dP7W4FVDhj431Pq00aaJVRHfuzN+HzwMrfk2iI8tY6Hrm2H88a5b2lfTsWeiXzhETfsMwCkxUFPzxR9a2vAo/eLW2d2/4+edsI3g3bMiYyteXxokIzJ7N1vLt+HJmObZsC+VLz0V4vp0GJ09mv9CaNTBoEBw8yF+rfEC980ql2w2wfTt6dwG/hHv2TP2NcFI50alXrsLft296OSO/Y8JvGEaBadRIPf70yVg4C+Hv00dTeDZvTt+emqqlbHyTdUVEaKiHCRNgwQKWt76Ow4e11M7XIZcSevwo/Pe/WS9y6BB07w67duGZ8iUz90enC75vuW0bGcKf6fqFhczXJ5kqw7uze3fWPuzt2/XmVlRhHjDhNwyjEIiK0nFJmcM9ee3chUzCD+r1e9m2TcXfJ/w8+qjW1rnnHhg8mD9G3gNo/N8zaAhTy10Nf/87vPdexkXmz1djPv+c3R3/RHKy3qh8dvuuQ+3aGm8pTI//+HFYuJC6W35id4XmNO5WDcjIGl2wAAYP1nnoL7ig8C57Jkz4DcMoMFkE1MuxYxmDu3Kjdm0VvZ070Rm6qlb1JtYrvoyeZs2AI0e0RsPOnaqWEyfStLlK2BVXwOVXhjD6+P9YX7Mvqfc/lPH4sWiRPiZ06cKWLdrUuLEufVNJbt+O5tY3aVK4Hv/990OPHvRL+p7Ypr2yjBPzeOCSS7RP+ocfMt3cigCbbN0wjAKTk/AfP35mjz8sDOrU8Qq/c1rLIZPH78vhb9YMiImBtDR4//30p4MLL4S334bRo/XJYP78Uvzjo/v5/ORIDZxfcAEsXKj1gMqWTRd+75gpQkLIyOUHDfcU1ujdQ4fggw841ncEr/7Ujrajr6F9A+2kXrxY69bt369zwQwcWDiXzCvm8RuGUWDq11cR9XXwJifr60zC7zs2PZFm4ED1uL2u/saNOlirWjXg++9VNbt3Tz82IkLnUgkP18FP77wDPcYNJY4qJL33id4oFi9OP2bzZt3X17cAZM/l37pVjyso48fDiROsvOZZHuMpKvdqjXN6s/rqK/jmG73XFWVsb+w7SQAADY9JREFU34cJv2EYBSY8XFMsfQLqG8yVV+FPr8h8ySW6nDIFUOFv1gzN4pk5U28MZ5iiqme/UnzBpYRP+1pHex07Bt20bMSWLSr0oaEZ+2cR/pYtNURU0GkYV63SCV4GDWKt0wJwvv6Ma6/VKtQvvqjpqdWrF+xSZ4MJv2EYhUJmAfWVb8iL8Ddvrk8KCQno3aNHD50ii0zCv3693h2GDTvj+Tp2hCnhVxN24jhcc402ej3+LVsy4vs+GjWCAwe8g359U0H+8EPOJ58xQ9310/HJJ2pESgo8+SQ7dujTUN26unnwYBX748fz9HH8ggm/YRiFwtkK/4ABGln56Sdvw2WXwYoVJK7czK5dMDRklhbqCQvLk1KWKgUne/Tj/+o+pb221apBkyaIaKjHF9/34ZsOYNky1C1v0SJn4U9NhTFj9Knkgw9yvrjHA//4B7Rrpzerbt3Yvl1FP8zboxoWBldeqe9N+A3DKNFERWk65xVXwEMPaVtehL9HD43P//ijt8FblCf+nSlEcILLJ43S8M6sWRnxkjPQu4/jnn2PkDh/OfLdNHbsdBw8qE8Vp3r8Xbro8rffvA1Dhuhd6MQJXX/qKXj9dTXwwAH9oH/+M3z5ZfYLz5ypfQQPPaQZSuiDyqlm/+1v8OST+tkDgoj45QW8BxwAVmdqiwRmAZu8yyp5OVenTp3EMIzizQcfiIBIuXK6BJG5c/N27JAhIq1bZ2ro2FEONO8lA/hRT/Ttt/myZcYMPaxnT5GWLfX9RRfp8ptvsu8fFSUyerR35bvvdMdZs0ROnBApU0YkNFSkRw+RypVF4uL0xOHhIjNnZj3RhReK1KwpcvJkelOjRiJXX50v8wsNYInkoKn+9PjfB059kHkYiBGRpkCMd90wjHOA0aM1q2b7dp1fpG9f7SvNCwMH6qCm9AnYR4yg6sZfuZpJSHi4DtrKB/36acFOj0dz9Xv2VJsgu8cP6vWne/x9++oTxvff6+CvpCQ8HoFff4XLL4cqVbQSaMuW2lPr68netUvbb75Z401oCGvXrjw/qBQdOd0NCusFRJHV498A1Pa+rw1syMt5zOM3jHObJUvUyf7oI2/DwoUiIKmEiPTtW+Dzb9umjrtzIklJ2bc//7xe/8ABb8PIkSI1akjq3ffKScLlVt6UNJwseGFBxkELFuhBzzyj66+8ousbNqTvsnu3Nr35ZoE/wllBADz+nKgpIr57+j6gZm47Ouducc4tcc4tiY2NLRrrDMMICNHRmq8fE6PrJ9t14QDVCcVTKInuDRtqCZ9LL802/S+QQ5z/zjvhwAHcG//HAnrS95PbaFttH/+dnyko36OH1op47jkSdiVw8pMp0LYtSfWb8e23WjVi6VLdtbh5/AHr3PXejeQ028eLSGcR6Vw9EImuhmEUGaGhmkn544/aO7BsRQgz8BbgL6QRTrffnp4lmo2OHXUwVXpV6EGDoEULQlJTmBUylBEjYNj1NfjmGy3jnM6//w2HD7O1x9WEL/qFQ/0vY/hwnVFx7Fjt6Aa98RQnilr49zvnagN4lweK+PqGYRRTBg3SEbybN2vVhpe5l8Sxd6kq+5kKFfT+8uabOrgK57QQHLC/w3AqVtQ+g9RU+PjjTAd26gT//jfRu6YRgnDBe5fx00+aBPT11xlzumQeKVwcKGrh/wa4wfv+BmBqEV/fMIxiiq9ezY8/qvAnNutA2Xde1dFPRcCzz6roP/WUru8ecQttWEWzy3V2sDZtoHNn+PDDrMfF3fYo73Ejv1UexOJjrRgzBu64Ay66CD77DP7yF600UazIKfBfGC9gErAXSAF2AWOBqmg2zybgRyAyL+eyzl3DOPfxeEQaNBDp0EGkfHmRsWOL3oYbbhApVUr7Z8eN047Z1asztj/7rLZt25bR9sMP3uzPHzyyerVISkqRm50rFHXnrohcJSK1RSRcROqJyLsickhEBopIUxEZJCJx/rq+YRglC+fU61++XCs3PPhg0dvw9NNakv+qq+CZZzR7s3XrjO2jRuny668z2nwdwp27OFq3zhihW5yxkbuGYRQbHn9cyyyvWJEx3WJRUrs2vPyylm9wLvtkXk2basgnc7me337T9sqVi9bWglAC7k2GYQQLUVFaZjmQXH+9DiZr1y7nTtlRo+A//9HyQdWqabl/X223koIJv2EYRiac04m+cuOqq/RJ4I8/YPZsLenjGwdQUjDhNwzDyActW2qVBud0et433sio/lxSMOE3DMPIJ87psmlTeOmlwNpyNljnrmEYRpBhwm8YhhFkmPAbhmEEGSb8hmEYQYYJv2EYRpBhwm8YhhFkmPAbhmEEGSb8hmEYQYbTyp3FG+dcLLD9LA+vBhwsRHMKi+JqFxRf28yu/FFc7YLia9u5ZldDEck2hWGJEP6C4JxbIiKdA23HqRRXu6D42mZ25Y/iahcUX9uCxS4L9RiGYQQZJvyGYRhBRjAI//hAG5ALxdUuKL62mV35o7jaBcXXtqCw65yP8RuGYRhZCQaP3zAMw8iECb9hGEaQcU4Lv3NumHNug3Nus3Pu4QDaUd85N8c5t9Y5t8Y5d4+3fZxzbrdzboX3dUEAbNvmnFvlvf4Sb1ukc26Wc26Td1mliG1qnuk7WeGcS3DO3Ruo78s5955z7oBzbnWmthy/I6e86v2bW+mc61jEdj3vnFvvvfZXzrnK3vYo51xSpu/urSK2K9ffzjn3iPf72uCcG1rEdk3OZNM259wKb3tRfl+56YP//sZE5Jx8AaHAFuA8oBTw+/+3d68hUpVxHMe/P9Sk0oyuiFauYYFBqUhEpEFFZFRrBWJU2gUiqBcVEcFC9SooKKHMgihqY60Iu+yLCqnAepEabXkpS82ClHWFortdXH+9eJ6J2XFn7LJzzrTz/8CwZ56d2f3P/zzzn3OeOec5wMySYpkMzMnLE4GtwEzgPuDOkvP0FXBMTduDwN15+W7ggZLX427gpLLyBcwH5gCbD5Yj4GLgDUDAWcC6guO6EBiblx+oimta9eNKyNew6y6/DzYA44GO/J4dU1RcNb9/CLinhHzVqw9N62OjeYv/TGC77R22fwdeADrLCMR2v+2+vPwjsAWYUkYsf1Mn8GxefhZYWGIs5wNf2P63Z27/Z7bfBb6taa6Xo06g28la4EhJk4uKy/Zq2/vy3bXA1Gb8738aVwOdwAu2f7P9JbCd9N4tNC5JAhYBzzfjfzfSoD40rY+N5sI/Bfi66v5OWqDYSpoGzAbW5aZb8+7a00UPqWQGVkv6UNJNue142/15eTdwfAlxVSxm6Jux7HxV1MtRK/W7G0hbhhUdkj6StEbSvBLiGW7dtUq+5gEDtrdVtRWer5r60LQ+NpoLf8uRNAFYBdxm+wfgceBkYBbQT9rVLNo5tucAC4BbJM2v/qXTvmUpx/xKOgS4DHgpN7VCvg5QZo7qkdQF7AN6clM/cKLt2cAdwEpJRxQYUkuuuypXMXQDo/B8DVMf/jLSfWw0F/5dwAlV96fmtlJIGkdaqT22XwawPWB70PZ+4EmatIvbiO1d+ece4JUcw0Bl1zH/3FN0XNkCoM/2QI6x9HxVqZej0vudpOuAS4Crc8EgD6V8k5c/JI2ln1JUTA3WXSvkayxwBfBipa3ofA1XH2hiHxvNhf8DYIakjrzluBjoLSOQPH74FLDF9sNV7dXjcpcDm2uf2+S4Dpc0sbJM+mJwMylPS/PDlgKvFRlXlSFbYWXnq0a9HPUCS/KRF2cB31ftrjedpIuAu4DLbP9S1X6spDF5eTowA9hRYFz11l0vsFjSeEkdOa71RcWVXQB8ZntnpaHIfNWrDzSzjxXxrXVZN9K331tJn9ZdJcZxDmk3bSPwcb5dDDwHbMrtvcDkguOaTjqiYgPwSSVHwNHA28A24C3gqBJydjjwDTCpqq2UfJE+fPqBP0jjqTfWyxHpSIvHcp/bBMwtOK7tpPHfSj97Ij/2yryOPwb6gEsLjqvuugO6cr4+BxYUGVdufwa4ueaxRearXn1oWh+LKRtCCKHNjOahnhBCCMOIwh9CCG0mCn8IIbSZKPwhhNBmovCHEEKbGVt2ACG0GkmDpMPkxpHOfu0GljmdfBTC/14U/hAOtNf2LABJxwErgSOAe0uNKoQREkM9ITTgNJXFTaQJxpTnaX9PUl++nQ0gqVvSX7OYSuqR1CnpNEnr85zuGyXNKOu1hFARJ3CFUEPST7Yn1LR9B5wK/Ajst/1rLuLP254r6VzgdtsLJU0inX05A1gGrLXdk6cOGWN7b7GvKIShYqgnhH9mHLBc0ixgkDxxl+01klZIOpZ0uv8q2/skvQ90SZoKvOyh0/6GUIoY6gnhIPIkXYOk2RFvBwaAM4C5pKu7VXQD1wDXA08D2F5Jmlp6L/C6pPOKizyE4cUWfwgN5C34J4Dltp2HcXba3i9pKenSkBXPkGaW3G370/z86cAO249IOhE4HXin0BcRQo0o/CEc6FCli25XDud8DqhMl7sCWCVpCfAm8HPlSbYHJG0BXq36W4uAayX9QbqK0v0FxB9CQ/HlbggjRNJhpOP/59j+vux4QqgnxvhDGAGSLiBdJPvRKPqh1cUWfwghtJnY4g8hhDYThT+EENpMFP4QQmgzUfhDCKHNROEPIYQ28yftBY4JkCP7vAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHWak5t1M4Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calc the accuracy score by converting the predicted price to 0 or 1 (0 indicates price went down, 1 indicates up)\n",
        "def get_accuracy(model, data):\n",
        "  y_test = data[\"y_test\"]\n",
        "  X_test = data[\"X_test\"]\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "  y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "  y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
        "  y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
        "  return accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwBEAPgSNMPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83094fb4-2c55-4a95-eac5-0e81d73c109c"
      },
      "source": [
        "print(str(LOOKUP_STEP) + \":\", \"Accuracy Score:\", get_accuracy(model, data))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: Accuracy Score: 0.5062586926286509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVCtcacg90i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loop_training():\n",
        "  #lookout_steps (1 is next day)\n",
        "  LOOKUP_STEPS = [1, 2, 3, 4, 5, 7]#14, 21, 28, 42, 56, 70]\n",
        "  # Window size or the sequence length\n",
        "  N_STEPS = 100\n",
        "  # Lookup step, 1 is the next day\n",
        "  LOOKUP_STEP = 1\n",
        "  # test ratio size, 0.2 is 20%\n",
        "  TEST_SIZE = 0.2\n",
        "  # features to use\n",
        "  FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "  # date now\n",
        "  date_now = time.strftime(\"%Y-%m-%d\")\n",
        "  ### model parameters\n",
        "  N_LAYERS = 3\n",
        "  # LSTM cell\n",
        "  CELL = LSTM\n",
        "  # 256 LSTM neurons\n",
        "  UNITS = 256\n",
        "  # 40% dropout\n",
        "  DROPOUT = 0.4\n",
        "  # whether to use bidirectional RNNs\n",
        "  BIDIRECTIONAL = False\n",
        "  ### training parameters\n",
        "  # mean absolute error loss\n",
        "  # LOSS = \"mae\"\n",
        "  # huber loss\n",
        "  LOSS = \"huber_loss\"\n",
        "  OPTIMIZER = \"adam\"\n",
        "  BATCH_SIZE = 64\n",
        "  EPOCHS = 100\n",
        "  # Apple stock market\n",
        "  ticker = \"AAL\"\n",
        "  ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "  # model name to save, making it as unique as possible based on parameters\n",
        "  model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "  if BIDIRECTIONAL:\n",
        "      model_name += \"-b\"\n",
        "  \n",
        "  \n",
        "\n",
        "  # construct the model\n",
        "  for num in LOOKUP_STEPS:\n",
        "    LOOKUP_STEP = num\n",
        "    # load the data\n",
        "    data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "    # save the dataframe\n",
        "    data[\"df\"].to_csv(ticker_data_filename)\n",
        "    model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS, dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "    # some tensorflow callbacks\n",
        "    checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=0)\n",
        "    tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "    history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        epochs=EPOCHS,\n",
        "                        validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                        callbacks=[checkpointer, tensorboard],\n",
        "                        verbose=1)\n",
        "\n",
        "    model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
        "\n",
        "\n",
        "    #calculate mean absolute error\n",
        "    data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                    feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "    # evaluate the model\n",
        "    mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "    # calculate the mean absolute error (inverse scaling)\n",
        "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "    print(\"Mean Absolute Error:\", mean_absolute_error)\n",
        "    #plot\n",
        "    plot_graph(model, data)\n",
        "    #predict\n",
        "    # predict the future price\n",
        "    future_price = predict(model, data)\n",
        "    print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
        "    accuracy = get_accuracy(model, data)\n",
        "    print(str(LOOKUP_STEP) + \":\", \"Accuracy Score:\", accuracy)\n",
        "    foo = model_name + \" \" + str(LOOKUP_STEP) + \" \" + str(round(future_price, 2)) + \" \" + str(round(mean_absolute_error, 2)) + \" \" + str(round(accuracy, 2))\n",
        "    write_results(foo)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6R2ttFlkAHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_results(string):\n",
        "  with open('/content/drive/My Drive/ml_trading/result.txt', 'a') as f:\n",
        "    f.write(string + \"\\n\")\n",
        "    f.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhVI1NLtiwA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "553c4e0d-1474-4ca4-e8fd-93095a17d2f0"
      },
      "source": [
        "loop_training()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 2/45 [>.............................] - ETA: 8s - loss: 0.0766 - mean_absolute_error: 0.2916WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.153957). Check your callbacks.\n",
            "45/45 [==============================] - 7s 151ms/step - loss: 0.0130 - mean_absolute_error: 0.1122 - val_loss: 0.0046 - val_mean_absolute_error: 0.0685\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0052 - mean_absolute_error: 0.0740 - val_loss: 0.0031 - val_mean_absolute_error: 0.0578\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0042 - mean_absolute_error: 0.0658 - val_loss: 0.0023 - val_mean_absolute_error: 0.0485\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0033 - mean_absolute_error: 0.0592 - val_loss: 0.0013 - val_mean_absolute_error: 0.0380\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0025 - mean_absolute_error: 0.0514 - val_loss: 0.0011 - val_mean_absolute_error: 0.0342\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 0.0024 - mean_absolute_error: 0.0509 - val_loss: 9.1912e-04 - val_mean_absolute_error: 0.0313\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0018 - mean_absolute_error: 0.0434 - val_loss: 6.4028e-04 - val_mean_absolute_error: 0.0268\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0019 - mean_absolute_error: 0.0441 - val_loss: 8.4485e-04 - val_mean_absolute_error: 0.0305\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 0.0017 - mean_absolute_error: 0.0414 - val_loss: 4.9548e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0016 - mean_absolute_error: 0.0403 - val_loss: 8.6548e-04 - val_mean_absolute_error: 0.0306\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0014 - mean_absolute_error: 0.0390 - val_loss: 8.1547e-04 - val_mean_absolute_error: 0.0307\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.0015 - mean_absolute_error: 0.0388 - val_loss: 4.0650e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0365 - val_loss: 3.8042e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 7s 154ms/step - loss: 0.0012 - mean_absolute_error: 0.0360 - val_loss: 3.3811e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0355 - val_loss: 4.7891e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0013 - mean_absolute_error: 0.0368 - val_loss: 9.7331e-04 - val_mean_absolute_error: 0.0353\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0360 - val_loss: 3.5823e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.0010 - mean_absolute_error: 0.0324 - val_loss: 3.2774e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0011 - mean_absolute_error: 0.0333 - val_loss: 3.6252e-04 - val_mean_absolute_error: 0.0200\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 0.0011 - mean_absolute_error: 0.0336 - val_loss: 7.1196e-04 - val_mean_absolute_error: 0.0287\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0010 - mean_absolute_error: 0.0329 - val_loss: 9.4357e-04 - val_mean_absolute_error: 0.0334\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.0012 - mean_absolute_error: 0.0355 - val_loss: 3.1378e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0331 - val_loss: 5.2311e-04 - val_mean_absolute_error: 0.0242\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 9.8531e-04 - mean_absolute_error: 0.0321 - val_loss: 4.5065e-04 - val_mean_absolute_error: 0.0224\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.8406e-04 - mean_absolute_error: 0.0304 - val_loss: 3.2685e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 8.5079e-04 - mean_absolute_error: 0.0298 - val_loss: 2.6729e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 0.0010 - mean_absolute_error: 0.0327 - val_loss: 2.8529e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 5s 111ms/step - loss: 8.5034e-04 - mean_absolute_error: 0.0296 - val_loss: 2.9328e-04 - val_mean_absolute_error: 0.0180\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 9.1971e-04 - mean_absolute_error: 0.0310 - val_loss: 4.4014e-04 - val_mean_absolute_error: 0.0221\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 8.6197e-04 - mean_absolute_error: 0.0297 - val_loss: 2.4006e-04 - val_mean_absolute_error: 0.0162\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 8.4660e-04 - mean_absolute_error: 0.0296 - val_loss: 3.0437e-04 - val_mean_absolute_error: 0.0177\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 9.0054e-04 - mean_absolute_error: 0.0308 - val_loss: 2.6000e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.9138e-04 - mean_absolute_error: 0.0305 - val_loss: 3.3754e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.0665e-04 - mean_absolute_error: 0.0292 - val_loss: 4.1570e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.7027e-04 - mean_absolute_error: 0.0299 - val_loss: 3.1652e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 7.9951e-04 - mean_absolute_error: 0.0291 - val_loss: 2.4030e-04 - val_mean_absolute_error: 0.0164\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.2135e-04 - mean_absolute_error: 0.0294 - val_loss: 2.7697e-04 - val_mean_absolute_error: 0.0169\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 7.9557e-04 - mean_absolute_error: 0.0289 - val_loss: 3.9090e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 8.4280e-04 - mean_absolute_error: 0.0297 - val_loss: 2.4089e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 6.9357e-04 - mean_absolute_error: 0.0268 - val_loss: 2.1041e-04 - val_mean_absolute_error: 0.0149\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 7.3960e-04 - mean_absolute_error: 0.0281 - val_loss: 2.4841e-04 - val_mean_absolute_error: 0.0162\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 7.1533e-04 - mean_absolute_error: 0.0272 - val_loss: 2.0206e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 7.3790e-04 - mean_absolute_error: 0.0280 - val_loss: 2.9544e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.9400e-04 - mean_absolute_error: 0.0269 - val_loss: 2.5073e-04 - val_mean_absolute_error: 0.0171\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.0202e-04 - mean_absolute_error: 0.0271 - val_loss: 2.3111e-04 - val_mean_absolute_error: 0.0167\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 7.6097e-04 - mean_absolute_error: 0.0283 - val_loss: 2.6134e-04 - val_mean_absolute_error: 0.0167\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.6679e-04 - mean_absolute_error: 0.0263 - val_loss: 2.1174e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - 6s 122ms/step - loss: 7.3437e-04 - mean_absolute_error: 0.0279 - val_loss: 2.0133e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.1758e-04 - mean_absolute_error: 0.0257 - val_loss: 2.4145e-04 - val_mean_absolute_error: 0.0159\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 7.8639e-04 - mean_absolute_error: 0.0288 - val_loss: 3.5202e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.9784e-04 - mean_absolute_error: 0.0276 - val_loss: 2.6246e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.0202e-04 - mean_absolute_error: 0.0272 - val_loss: 2.2656e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.6370e-04 - mean_absolute_error: 0.0267 - val_loss: 4.3633e-04 - val_mean_absolute_error: 0.0225\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.7263e-04 - mean_absolute_error: 0.0265 - val_loss: 2.2234e-04 - val_mean_absolute_error: 0.0150\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 6.2525e-04 - mean_absolute_error: 0.0254 - val_loss: 2.1045e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.5146e-04 - mean_absolute_error: 0.0262 - val_loss: 2.0229e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 6.1441e-04 - mean_absolute_error: 0.0255 - val_loss: 1.9123e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.6462e-04 - mean_absolute_error: 0.0266 - val_loss: 3.4608e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.8673e-04 - mean_absolute_error: 0.0267 - val_loss: 2.8274e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 60/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.5930e-04 - mean_absolute_error: 0.0264 - val_loss: 2.0248e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 61/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.6217e-04 - mean_absolute_error: 0.0266 - val_loss: 2.3597e-04 - val_mean_absolute_error: 0.0162\n",
            "Epoch 62/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.7029e-04 - mean_absolute_error: 0.0267 - val_loss: 3.1034e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 63/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.2442e-04 - mean_absolute_error: 0.0256 - val_loss: 2.0776e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 64/100\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 5.9301e-04 - mean_absolute_error: 0.0252 - val_loss: 1.8327e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 65/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.6378e-04 - mean_absolute_error: 0.0249 - val_loss: 2.6822e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 66/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 5.9225e-04 - mean_absolute_error: 0.0252 - val_loss: 2.3373e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 67/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 6.0396e-04 - mean_absolute_error: 0.0250 - val_loss: 2.5585e-04 - val_mean_absolute_error: 0.0171\n",
            "Epoch 68/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.4621e-04 - mean_absolute_error: 0.0264 - val_loss: 8.1042e-04 - val_mean_absolute_error: 0.0355\n",
            "Epoch 69/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.3466e-04 - mean_absolute_error: 0.0262 - val_loss: 2.9069e-04 - val_mean_absolute_error: 0.0170\n",
            "Epoch 70/100\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 6.3661e-04 - mean_absolute_error: 0.0262 - val_loss: 1.6685e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 71/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 6.2505e-04 - mean_absolute_error: 0.0259 - val_loss: 1.9182e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 72/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.4537e-04 - mean_absolute_error: 0.0243 - val_loss: 2.0708e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 73/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.9681e-04 - mean_absolute_error: 0.0249 - val_loss: 2.5441e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 74/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.3948e-04 - mean_absolute_error: 0.0241 - val_loss: 1.7874e-04 - val_mean_absolute_error: 0.0135\n",
            "Epoch 75/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.6751e-04 - mean_absolute_error: 0.0244 - val_loss: 1.7156e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 76/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.7544e-04 - mean_absolute_error: 0.0244 - val_loss: 2.1324e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 77/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.4930e-04 - mean_absolute_error: 0.0240 - val_loss: 1.9171e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 78/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.4564e-04 - mean_absolute_error: 0.0263 - val_loss: 1.8911e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 79/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.2456e-04 - mean_absolute_error: 0.0237 - val_loss: 1.7159e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 80/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.4164e-04 - mean_absolute_error: 0.0238 - val_loss: 3.2547e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 81/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.4222e-04 - mean_absolute_error: 0.0243 - val_loss: 1.8695e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 82/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.8448e-04 - mean_absolute_error: 0.0251 - val_loss: 1.8251e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 83/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.4682e-04 - mean_absolute_error: 0.0243 - val_loss: 1.7017e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 84/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 6.0206e-04 - mean_absolute_error: 0.0255 - val_loss: 2.4111e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 85/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.7301e-04 - mean_absolute_error: 0.0249 - val_loss: 2.1504e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 86/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.3070e-04 - mean_absolute_error: 0.0238 - val_loss: 1.6913e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 87/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.0047e-04 - mean_absolute_error: 0.0231 - val_loss: 1.7815e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 88/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 5.2545e-04 - mean_absolute_error: 0.0239 - val_loss: 2.2466e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 89/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.7100e-04 - mean_absolute_error: 0.0248 - val_loss: 2.0684e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 90/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 4.9112e-04 - mean_absolute_error: 0.0230 - val_loss: 1.8809e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 91/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.7521e-04 - mean_absolute_error: 0.0247 - val_loss: 1.8463e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 92/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 4.8922e-04 - mean_absolute_error: 0.0232 - val_loss: 1.7072e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 93/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.2087e-04 - mean_absolute_error: 0.0260 - val_loss: 1.7953e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 94/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.9427e-04 - mean_absolute_error: 0.0252 - val_loss: 2.1833e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 95/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.0573e-04 - mean_absolute_error: 0.0240 - val_loss: 2.2885e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 96/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 5.2491e-04 - mean_absolute_error: 0.0238 - val_loss: 1.6651e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 97/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 4.7920e-04 - mean_absolute_error: 0.0230 - val_loss: 1.9103e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 98/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 4.7193e-04 - mean_absolute_error: 0.0227 - val_loss: 2.7416e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 99/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.4445e-04 - mean_absolute_error: 0.0247 - val_loss: 1.7319e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 100/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 5.6107e-04 - mean_absolute_error: 0.0253 - val_loss: 2.2094e-04 - val_mean_absolute_error: 0.0163\n",
            "Mean Absolute Error: 2.8931765907354623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Future price after 1 days is 17.74$\n",
            "1: Accuracy Score: 0.5396383866481224\n",
            "Epoch 1/100\n",
            " 2/45 [>.............................] - ETA: 7s - loss: 0.0582 - mean_absolute_error: 0.2393WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.129073). Check your callbacks.\n",
            "45/45 [==============================] - 6s 142ms/step - loss: 0.0128 - mean_absolute_error: 0.1092 - val_loss: 0.0047 - val_mean_absolute_error: 0.0714\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.0055 - mean_absolute_error: 0.0766 - val_loss: 0.0043 - val_mean_absolute_error: 0.0675\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0044 - mean_absolute_error: 0.0684 - val_loss: 0.0043 - val_mean_absolute_error: 0.0696\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0040 - mean_absolute_error: 0.0644 - val_loss: 0.0018 - val_mean_absolute_error: 0.0444\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.0030 - mean_absolute_error: 0.0561 - val_loss: 0.0014 - val_mean_absolute_error: 0.0382\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.0024 - mean_absolute_error: 0.0501 - val_loss: 9.8460e-04 - val_mean_absolute_error: 0.0329\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.0021 - mean_absolute_error: 0.0471 - val_loss: 0.0012 - val_mean_absolute_error: 0.0370\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0451 - val_loss: 7.4633e-04 - val_mean_absolute_error: 0.0294\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.0018 - mean_absolute_error: 0.0431 - val_loss: 6.0606e-04 - val_mean_absolute_error: 0.0263\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 5s 109ms/step - loss: 0.0017 - mean_absolute_error: 0.0423 - val_loss: 6.5859e-04 - val_mean_absolute_error: 0.0273\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0017 - mean_absolute_error: 0.0416 - val_loss: 5.2976e-04 - val_mean_absolute_error: 0.0243\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0015 - mean_absolute_error: 0.0402 - val_loss: 5.5531e-04 - val_mean_absolute_error: 0.0242\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0013 - mean_absolute_error: 0.0366 - val_loss: 6.0604e-04 - val_mean_absolute_error: 0.0253\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.0013 - mean_absolute_error: 0.0366 - val_loss: 8.5784e-04 - val_mean_absolute_error: 0.0317\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.0016 - mean_absolute_error: 0.0404 - val_loss: 0.0015 - val_mean_absolute_error: 0.0442\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0013 - mean_absolute_error: 0.0364 - val_loss: 5.2157e-04 - val_mean_absolute_error: 0.0240\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0013 - mean_absolute_error: 0.0372 - val_loss: 7.9525e-04 - val_mean_absolute_error: 0.0293\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0013 - mean_absolute_error: 0.0367 - val_loss: 7.1789e-04 - val_mean_absolute_error: 0.0293\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0012 - mean_absolute_error: 0.0349 - val_loss: 9.9679e-04 - val_mean_absolute_error: 0.0338\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0014 - mean_absolute_error: 0.0375 - val_loss: 6.7331e-04 - val_mean_absolute_error: 0.0279\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0345 - val_loss: 4.8473e-04 - val_mean_absolute_error: 0.0234\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.0012 - mean_absolute_error: 0.0352 - val_loss: 9.1789e-04 - val_mean_absolute_error: 0.0337\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.0012 - mean_absolute_error: 0.0354 - val_loss: 4.3299e-04 - val_mean_absolute_error: 0.0218\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0010 - mean_absolute_error: 0.0324 - val_loss: 5.3228e-04 - val_mean_absolute_error: 0.0242\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 9.9052e-04 - mean_absolute_error: 0.0324 - val_loss: 4.1599e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.0012 - mean_absolute_error: 0.0350 - val_loss: 6.6722e-04 - val_mean_absolute_error: 0.0271\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 9.8983e-04 - mean_absolute_error: 0.0323 - val_loss: 4.6696e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 9.9107e-04 - mean_absolute_error: 0.0321 - val_loss: 5.3977e-04 - val_mean_absolute_error: 0.0239\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.0011 - mean_absolute_error: 0.0334 - val_loss: 4.2435e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 0.0010 - mean_absolute_error: 0.0332 - val_loss: 3.9893e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 9.5616e-04 - mean_absolute_error: 0.0316 - val_loss: 3.7634e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.0010 - mean_absolute_error: 0.0333 - val_loss: 3.6587e-04 - val_mean_absolute_error: 0.0200\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 8.8610e-04 - mean_absolute_error: 0.0303 - val_loss: 3.9057e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 6s 140ms/step - loss: 9.3469e-04 - mean_absolute_error: 0.0314 - val_loss: 3.7916e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 9.2533e-04 - mean_absolute_error: 0.0310 - val_loss: 3.6842e-04 - val_mean_absolute_error: 0.0199\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 8.9204e-04 - mean_absolute_error: 0.0308 - val_loss: 4.1584e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 8.9560e-04 - mean_absolute_error: 0.0308 - val_loss: 3.5523e-04 - val_mean_absolute_error: 0.0200\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 9.1428e-04 - mean_absolute_error: 0.0305 - val_loss: 3.7702e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 8.4602e-04 - mean_absolute_error: 0.0299 - val_loss: 4.1903e-04 - val_mean_absolute_error: 0.0222\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 9.4118e-04 - mean_absolute_error: 0.0312 - val_loss: 4.1583e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 9.4025e-04 - mean_absolute_error: 0.0314 - val_loss: 4.5251e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 7.8372e-04 - mean_absolute_error: 0.0285 - val_loss: 3.6048e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 8.5172e-04 - mean_absolute_error: 0.0301 - val_loss: 3.7407e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 8.6062e-04 - mean_absolute_error: 0.0299 - val_loss: 3.4040e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 9.3742e-04 - mean_absolute_error: 0.0313 - val_loss: 3.6424e-04 - val_mean_absolute_error: 0.0193\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 8.8088e-04 - mean_absolute_error: 0.0300 - val_loss: 4.3509e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 8.8592e-04 - mean_absolute_error: 0.0302 - val_loss: 4.1759e-04 - val_mean_absolute_error: 0.0224\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 8.9945e-04 - mean_absolute_error: 0.0305 - val_loss: 3.6636e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 8.1844e-04 - mean_absolute_error: 0.0294 - val_loss: 3.9598e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 8.3265e-04 - mean_absolute_error: 0.0289 - val_loss: 4.2439e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 9.3066e-04 - mean_absolute_error: 0.0315 - val_loss: 4.8036e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.5145e-04 - mean_absolute_error: 0.0283 - val_loss: 3.4730e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 7.5209e-04 - mean_absolute_error: 0.0281 - val_loss: 3.5793e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 8.3935e-04 - mean_absolute_error: 0.0293 - val_loss: 4.0158e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 8.2030e-04 - mean_absolute_error: 0.0293 - val_loss: 4.1600e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 7.5744e-04 - mean_absolute_error: 0.0283 - val_loss: 3.3326e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 7.8266e-04 - mean_absolute_error: 0.0290 - val_loss: 6.4520e-04 - val_mean_absolute_error: 0.0275\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 8.1112e-04 - mean_absolute_error: 0.0294 - val_loss: 3.5751e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 8.0979e-04 - mean_absolute_error: 0.0291 - val_loss: 3.4643e-04 - val_mean_absolute_error: 0.0199\n",
            "Epoch 60/100\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 7.5107e-04 - mean_absolute_error: 0.0280 - val_loss: 3.2919e-04 - val_mean_absolute_error: 0.0189\n",
            "Epoch 61/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.1914e-04 - mean_absolute_error: 0.0276 - val_loss: 3.2745e-04 - val_mean_absolute_error: 0.0184\n",
            "Epoch 62/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 6.9616e-04 - mean_absolute_error: 0.0272 - val_loss: 3.8272e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 63/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.1554e-04 - mean_absolute_error: 0.0274 - val_loss: 3.4930e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 64/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 8.4561e-04 - mean_absolute_error: 0.0297 - val_loss: 3.3943e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 65/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.3366e-04 - mean_absolute_error: 0.0279 - val_loss: 3.3731e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 66/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 7.3594e-04 - mean_absolute_error: 0.0277 - val_loss: 3.7163e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 67/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 7.4843e-04 - mean_absolute_error: 0.0284 - val_loss: 3.7167e-04 - val_mean_absolute_error: 0.0207\n",
            "Epoch 68/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 7.4896e-04 - mean_absolute_error: 0.0279 - val_loss: 3.1485e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 69/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 7.3140e-04 - mean_absolute_error: 0.0281 - val_loss: 3.0083e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 70/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.2394e-04 - mean_absolute_error: 0.0277 - val_loss: 4.0677e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 71/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.9488e-04 - mean_absolute_error: 0.0290 - val_loss: 3.6501e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 72/100\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 7.4721e-04 - mean_absolute_error: 0.0280 - val_loss: 2.9676e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 73/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 6.5480e-04 - mean_absolute_error: 0.0263 - val_loss: 3.3094e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 74/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 6.6486e-04 - mean_absolute_error: 0.0263 - val_loss: 3.2722e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 75/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.2664e-04 - mean_absolute_error: 0.0279 - val_loss: 3.1008e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 76/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 7.0233e-04 - mean_absolute_error: 0.0276 - val_loss: 3.1712e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 77/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.4815e-04 - mean_absolute_error: 0.0267 - val_loss: 3.8442e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 78/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.6631e-04 - mean_absolute_error: 0.0265 - val_loss: 6.9699e-04 - val_mean_absolute_error: 0.0285\n",
            "Epoch 79/100\n",
            "45/45 [==============================] - 5s 116ms/step - loss: 6.8537e-04 - mean_absolute_error: 0.0271 - val_loss: 2.8012e-04 - val_mean_absolute_error: 0.0170\n",
            "Epoch 80/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 6.8288e-04 - mean_absolute_error: 0.0269 - val_loss: 2.9554e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 81/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 6.9484e-04 - mean_absolute_error: 0.0271 - val_loss: 2.9485e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 82/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 6.3297e-04 - mean_absolute_error: 0.0265 - val_loss: 2.9548e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 83/100\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 6.3578e-04 - mean_absolute_error: 0.0263 - val_loss: 4.0423e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 84/100\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 6.5495e-04 - mean_absolute_error: 0.0268 - val_loss: 3.0961e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 85/100\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 6.7853e-04 - mean_absolute_error: 0.0272 - val_loss: 2.7567e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 86/100\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 6.4457e-04 - mean_absolute_error: 0.0261 - val_loss: 5.6335e-04 - val_mean_absolute_error: 0.0253\n",
            "Epoch 87/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 6.9311e-04 - mean_absolute_error: 0.0272 - val_loss: 3.4023e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 88/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 7.2713e-04 - mean_absolute_error: 0.0289 - val_loss: 2.8847e-04 - val_mean_absolute_error: 0.0175\n",
            "Epoch 89/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.6128e-04 - mean_absolute_error: 0.0267 - val_loss: 3.4338e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 90/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.6484e-04 - mean_absolute_error: 0.0266 - val_loss: 4.2451e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 91/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 6.4399e-04 - mean_absolute_error: 0.0263 - val_loss: 6.3591e-04 - val_mean_absolute_error: 0.0272\n",
            "Epoch 92/100\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 8.1866e-04 - mean_absolute_error: 0.0301 - val_loss: 4.5696e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 93/100\n",
            "45/45 [==============================] - 5s 108ms/step - loss: 6.8563e-04 - mean_absolute_error: 0.0273 - val_loss: 6.1273e-04 - val_mean_absolute_error: 0.0275\n",
            "Epoch 94/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.9032e-04 - mean_absolute_error: 0.0272 - val_loss: 3.4176e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 95/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.1275e-04 - mean_absolute_error: 0.0256 - val_loss: 6.2099e-04 - val_mean_absolute_error: 0.0266\n",
            "Epoch 96/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 7.2065e-04 - mean_absolute_error: 0.0274 - val_loss: 3.0508e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 97/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 6.4260e-04 - mean_absolute_error: 0.0266 - val_loss: 4.0291e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 98/100\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 6.1048e-04 - mean_absolute_error: 0.0257 - val_loss: 2.6800e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 99/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 5.9013e-04 - mean_absolute_error: 0.0251 - val_loss: 4.0128e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 100/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 5.8030e-04 - mean_absolute_error: 0.0253 - val_loss: 3.7064e-04 - val_mean_absolute_error: 0.0197\n",
            "Mean Absolute Error: 2.846521716474656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Future price after 2 days is 19.22$\n",
            "2: Accuracy Score: 0.47983310152990266\n",
            "Epoch 1/100\n",
            " 2/45 [>.............................] - ETA: 9s - loss: 0.0773 - mean_absolute_error: 0.2864WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.149582). Check your callbacks.\n",
            "45/45 [==============================] - 7s 149ms/step - loss: 0.0124 - mean_absolute_error: 0.1060 - val_loss: 0.0041 - val_mean_absolute_error: 0.0662\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0049 - mean_absolute_error: 0.0716 - val_loss: 0.0033 - val_mean_absolute_error: 0.0595\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0040 - mean_absolute_error: 0.0638 - val_loss: 0.0025 - val_mean_absolute_error: 0.0517\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0035 - mean_absolute_error: 0.0594 - val_loss: 0.0022 - val_mean_absolute_error: 0.0486\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.0029 - mean_absolute_error: 0.0547 - val_loss: 0.0021 - val_mean_absolute_error: 0.0490\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0021 - mean_absolute_error: 0.0471 - val_loss: 0.0012 - val_mean_absolute_error: 0.0361\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0022 - mean_absolute_error: 0.0474 - val_loss: 9.6164e-04 - val_mean_absolute_error: 0.0329\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0019 - mean_absolute_error: 0.0438 - val_loss: 0.0015 - val_mean_absolute_error: 0.0405\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 0.0017 - mean_absolute_error: 0.0414 - val_loss: 8.2625e-04 - val_mean_absolute_error: 0.0304\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0019 - mean_absolute_error: 0.0441 - val_loss: 0.0011 - val_mean_absolute_error: 0.0359\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.0017 - mean_absolute_error: 0.0419 - val_loss: 7.0595e-04 - val_mean_absolute_error: 0.0274\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 5s 110ms/step - loss: 0.0015 - mean_absolute_error: 0.0390 - val_loss: 7.3192e-04 - val_mean_absolute_error: 0.0283\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0015 - mean_absolute_error: 0.0397 - val_loss: 6.6442e-04 - val_mean_absolute_error: 0.0269\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0016 - mean_absolute_error: 0.0407 - val_loss: 6.7032e-04 - val_mean_absolute_error: 0.0270\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 0.0015 - mean_absolute_error: 0.0393 - val_loss: 6.1801e-04 - val_mean_absolute_error: 0.0258\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0013 - mean_absolute_error: 0.0370 - val_loss: 6.5694e-04 - val_mean_absolute_error: 0.0265\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0013 - mean_absolute_error: 0.0374 - val_loss: 6.7783e-04 - val_mean_absolute_error: 0.0268\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0014 - mean_absolute_error: 0.0381 - val_loss: 6.9788e-04 - val_mean_absolute_error: 0.0276\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0012 - mean_absolute_error: 0.0352 - val_loss: 5.6039e-04 - val_mean_absolute_error: 0.0245\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0012 - mean_absolute_error: 0.0354 - val_loss: 6.8125e-04 - val_mean_absolute_error: 0.0270\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0353 - val_loss: 6.3926e-04 - val_mean_absolute_error: 0.0262\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0014 - mean_absolute_error: 0.0385 - val_loss: 5.5560e-04 - val_mean_absolute_error: 0.0246\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0356 - val_loss: 6.2140e-04 - val_mean_absolute_error: 0.0262\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0012 - mean_absolute_error: 0.0353 - val_loss: 5.8678e-04 - val_mean_absolute_error: 0.0251\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0011 - mean_absolute_error: 0.0339 - val_loss: 5.5331e-04 - val_mean_absolute_error: 0.0247\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0336 - val_loss: 5.1021e-04 - val_mean_absolute_error: 0.0232\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0011 - mean_absolute_error: 0.0338 - val_loss: 5.6603e-04 - val_mean_absolute_error: 0.0244\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0339 - val_loss: 5.1754e-04 - val_mean_absolute_error: 0.0237\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0343 - val_loss: 7.9237e-04 - val_mean_absolute_error: 0.0299\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0010 - mean_absolute_error: 0.0328 - val_loss: 7.1123e-04 - val_mean_absolute_error: 0.0287\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 5s 116ms/step - loss: 0.0010 - mean_absolute_error: 0.0332 - val_loss: 4.8976e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0010 - mean_absolute_error: 0.0330 - val_loss: 7.6112e-04 - val_mean_absolute_error: 0.0293\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0011 - mean_absolute_error: 0.0335 - val_loss: 5.2126e-04 - val_mean_absolute_error: 0.0243\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0011 - mean_absolute_error: 0.0338 - val_loss: 4.9767e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 9.2939e-04 - mean_absolute_error: 0.0311 - val_loss: 5.0527e-04 - val_mean_absolute_error: 0.0235\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.0010 - mean_absolute_error: 0.0327 - val_loss: 5.2459e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 9.7533e-04 - mean_absolute_error: 0.0320 - val_loss: 6.2022e-04 - val_mean_absolute_error: 0.0267\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 0.0010 - mean_absolute_error: 0.0328 - val_loss: 4.8829e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 9.9855e-04 - mean_absolute_error: 0.0321 - val_loss: 5.5985e-04 - val_mean_absolute_error: 0.0249\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 9.3168e-04 - mean_absolute_error: 0.0318 - val_loss: 4.8721e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 9.5681e-04 - mean_absolute_error: 0.0319 - val_loss: 5.9426e-04 - val_mean_absolute_error: 0.0268\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0010 - mean_absolute_error: 0.0324 - val_loss: 6.2081e-04 - val_mean_absolute_error: 0.0252\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.0010 - mean_absolute_error: 0.0328 - val_loss: 4.8045e-04 - val_mean_absolute_error: 0.0224\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.0010 - mean_absolute_error: 0.0337 - val_loss: 5.7626e-04 - val_mean_absolute_error: 0.0249\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 9.0566e-04 - mean_absolute_error: 0.0310 - val_loss: 4.5648e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 9.7244e-04 - mean_absolute_error: 0.0316 - val_loss: 5.1663e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 9.1518e-04 - mean_absolute_error: 0.0309 - val_loss: 4.7251e-04 - val_mean_absolute_error: 0.0222\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.7844e-04 - mean_absolute_error: 0.0307 - val_loss: 4.6396e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 9.4111e-04 - mean_absolute_error: 0.0318 - val_loss: 4.7550e-04 - val_mean_absolute_error: 0.0218\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 9.2977e-04 - mean_absolute_error: 0.0312 - val_loss: 4.9391e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 8.8202e-04 - mean_absolute_error: 0.0300 - val_loss: 6.5359e-04 - val_mean_absolute_error: 0.0274\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.4609e-04 - mean_absolute_error: 0.0299 - val_loss: 4.5905e-04 - val_mean_absolute_error: 0.0219\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 9.0900e-04 - mean_absolute_error: 0.0311 - val_loss: 5.1898e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - 7s 160ms/step - loss: 8.7446e-04 - mean_absolute_error: 0.0308 - val_loss: 5.1832e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 9.1410e-04 - mean_absolute_error: 0.0311 - val_loss: 4.6260e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 8.6748e-04 - mean_absolute_error: 0.0303 - val_loss: 5.2652e-04 - val_mean_absolute_error: 0.0233\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 8.9978e-04 - mean_absolute_error: 0.0308 - val_loss: 5.4985e-04 - val_mean_absolute_error: 0.0254\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 8.4756e-04 - mean_absolute_error: 0.0301 - val_loss: 4.2549e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 8.2649e-04 - mean_absolute_error: 0.0295 - val_loss: 4.8919e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 60/100\n",
            " 2/45 [>.............................] - ETA: 2s - loss: 0.0010 - mean_absolute_error: 0.0337    "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}